{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Machine Learning  \n",
    "\n",
    "## Assignment 8: Linear Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can't learn technical subjects without hands-on practice. The assignments are an important part of the course. To submit this assignment you will need to make sure that you save your Jupyter notebook. \n",
    "\n",
    "Below are the links of 2 videos that explain:\n",
    "\n",
    "1. [How to save your Jupyter notebook](https://youtu.be/0aoLgBoAUSA) and,       \n",
    "2. [How to answer a question in a Jupyter notebook assignment](https://youtu.be/7j0WKhI3W4s)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment Learning Goals:\n",
    "\n",
    "By the end of the module, students are expected to:\n",
    "\n",
    "- Explain the general intuition behind linear models.\n",
    "- Explain the `fit` and `predict` paradigm of linear models.\n",
    "- Use `scikit-learn`'s `LogisticRegression` classifier.\n",
    "    - Use `fit`, `predict` and `predict_proba`.   \n",
    "    - Use `coef_` to interpret the model weights.\n",
    "- Explain the advantages and limitations of linear classifiers. \n",
    "- Apply scikit-learn regression model (e.g., Ridge) to regression problems.\n",
    "- Relate the Ridge hyperparameter `alpha` to the `LogisticRegression` hyperparameter `C`.\n",
    "\n",
    "\n",
    "This assignment covers [Module 8](https://ml-learn.mds.ubc.ca/en/module8) of the online course. You should complete this module before attempting this assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any place you see `...`, you must fill in the function, variable, or data to complete the code. Substitute the `None` with your completed code and answers then proceed to run the cell!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that some of the questions in this assignment will have hidden tests. This means that no feedback will be given as to the correctness of your solution. It will be left up to you to decide if your answer is sufficiently correct. These questions are worth 2 points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataTransformerRegistry.enable('default')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import libraries needed for this lab\n",
    "from hashlib import sha1\n",
    "\n",
    "import altair as alt\n",
    "import graphviz\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "from sklearn import tree\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.compose import make_column_transformer \n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.preprocessing import (\n",
    "    FunctionTransformer,\n",
    "    Normalizer,\n",
    "    OneHotEncoder,\n",
    "    StandardScaler,\n",
    "    normalize,\n",
    "    scale)\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix, classification_report\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn import set_config\n",
    "\n",
    "from scipy.stats import lognorm, loguniform, randint\n",
    "\n",
    "import test_assignment8 as t\n",
    "#alt.renderers.enable('mimetype')\n",
    "alt.data_transformers.disable_max_rows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Sentiment analysis on the IMDB dataset \n",
    "\n",
    "<img src=\"https://ia.media-imdb.com/images/M/MV5BMTk3ODA4Mjc0NF5BMl5BcG5nXkFtZTgwNDc1MzQ2OTE@._V1_.png\"  width = \"40%\" alt=\"404 image\" />\n",
    "\n",
    "In this exercise, you will carry out sentiment analysis on a real corpus, [the IMDB movie review dataset](https://www.kaggle.com/utathya/imdb-review-dataset).\n",
    "The starter code below loads the data CSV file (assuming that it's in the data directory) as a pandas DataFrame called `imdb_df`.\n",
    "\n",
    "We have done a bit of preprocessing on the dataset and we will use the train/test split that's already provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train</td>\n",
       "      <td>The world is facing imminent destruction and a...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train</td>\n",
       "      <td>What a horrible comedy. Totally lame. The supp...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train</td>\n",
       "      <td>Follow-up to 1973's far better \"Cleopatra Jone...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train</td>\n",
       "      <td>It was the Sixties, and anyone with long hair ...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train</td>\n",
       "      <td>this movie begins with an ordinary funeral... ...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    type                                             review label\n",
       "0  train  The world is facing imminent destruction and a...   neg\n",
       "1  train  What a horrible comedy. Totally lame. The supp...   neg\n",
       "2  train  Follow-up to 1973's far better \"Cleopatra Jone...   neg\n",
       "3  train  It was the Sixties, and anyone with long hair ...   neg\n",
       "4  train  this movie begins with an ordinary funeral... ...   neg"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "imdb_df = pd.read_csv(\"data/imdb_speed.csv\")\n",
    "train_df = imdb_df[imdb_df['type'] == \"train\"]\n",
    "test_df = imdb_df[imdb_df['type'] == \"test\"]\n",
    "display(train_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.1** <br> {points: 1}  \n",
    "\n",
    "Let's now separate our feature vectors from the target.\n",
    "\n",
    "Use the column `review` as your `X` and the `label` column as your target `y`. \n",
    "\n",
    "You will need to do this for both `train_df` and `test_df`.\n",
    "\n",
    "Save the results in objects named `X_train`, `y_train`, `X_test` and `y_test`. \n",
    "\n",
    "(Makes sure that all 4 of these objects are of type Pandas Series. We will be using `CountVectorizer` for future questions and this transformation requires an input of Pandas Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0e78c6cf5da63d77e76227158eb6161f",
     "grade": false,
     "grade_id": "cell-e2813ca2b1b4df7d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "X_train, y_train = train_df['review'], train_df['label']\n",
    "X_test, y_test = test_df['review'], test_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3d10e6491bf23a70f3fac0144b0d694a",
     "grade": true,
     "grade_id": "cell-de9b99c573bdb428",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_1_1(X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.2** <br> {points: 1}  \n",
    "\n",
    "What is the distribution of target values (`label`) in the train split? Your answer should be of type Pandas Series and saved in an object named `class_dist`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c8ec1841722fab35463d9646f3264757",
     "grade": false,
     "grade_id": "cell-a4221b3dc49430cc",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neg    5000\n",
       "pos    5000\n",
       "Name: label, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class_dist = y_train.value_counts()\n",
    "\n",
    "display(class_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "80393b3a0e1a87ae8695e9170599e303",
     "grade": true,
     "grade_id": "cell-dc5e6a320bf78d16",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_1_2(class_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.3** <br> {points: 1}  \n",
    "\n",
    "Do any of your columns have any null values? \n",
    "\n",
    "A) Yes\n",
    "\n",
    "B) No\n",
    "\n",
    "*Answer in the cell below using the uppercase letter associated with your answer. Place your answer between `\"\"`, assign the correct answer to an object called `answer1_3`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "91d22cd3e69d89097fb7c970754e7632",
     "grade": false,
     "grade_id": "cell-a80b52675ea3f75e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'B'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if X_train.isnull().sum() > 0 :\n",
    "    answer1_3 = \"A\"\n",
    "else :\n",
    "    answer1_3 = \"B\"\n",
    "\n",
    "display(answer1_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ab1054bc7d56380cece8dceb22a3a3cc",
     "grade": true,
     "grade_id": "cell-afed4860b4dadd44",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_1_3(answer1_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.4** <br> {points: 2}  \n",
    "\n",
    "***Challenge question!***\n",
    "\n",
    "How many words are present in each review? \n",
    "\n",
    "Add a column `review_wordcount` to the `train_df` dataframe and save this new dataframe as an object named `review_length_df`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3067a827edf8e5513b87b108ea751bc7",
     "grade": false,
     "grade_id": "cell-1726fe6021386d28",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "      <th>review_wordcount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train</td>\n",
       "      <td>The world is facing imminent destruction and a...</td>\n",
       "      <td>neg</td>\n",
       "      <td>662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train</td>\n",
       "      <td>What a horrible comedy. Totally lame. The supp...</td>\n",
       "      <td>neg</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train</td>\n",
       "      <td>Follow-up to 1973's far better \"Cleopatra Jone...</td>\n",
       "      <td>neg</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train</td>\n",
       "      <td>It was the Sixties, and anyone with long hair ...</td>\n",
       "      <td>neg</td>\n",
       "      <td>601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train</td>\n",
       "      <td>this movie begins with an ordinary funeral... ...</td>\n",
       "      <td>neg</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    type                                             review label  \\\n",
       "0  train  The world is facing imminent destruction and a...   neg   \n",
       "1  train  What a horrible comedy. Totally lame. The supp...   neg   \n",
       "2  train  Follow-up to 1973's far better \"Cleopatra Jone...   neg   \n",
       "3  train  It was the Sixties, and anyone with long hair ...   neg   \n",
       "4  train  this movie begins with an ordinary funeral... ...   neg   \n",
       "\n",
       "   review_wordcount  \n",
       "0               662  \n",
       "1                46  \n",
       "2               109  \n",
       "3               601  \n",
       "4               116  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "review_length_df = train_df.assign(review_wordcount = train_df['review'].str.split().str.len())\n",
    "\n",
    "display(review_length_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "de075eafcb94246e6e5f7944d362c57d",
     "grade": true,
     "grade_id": "cell-b38989bc28be88a3",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_1_4(review_length_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.5** <br> {points: 3}  \n",
    "\n",
    "What is the average word count for each review label (pos and neg)?\n",
    "\n",
    "Save the average negative label word count and the average positive label word count to the nearest full number in objects named `neg_wc_avg` and `pos_wc_avg` respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "27b8d8a06bcbe59e64e1434d555c0897",
     "grade": false,
     "grade_id": "cell-ccb66cda36fd0f91",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_wordcount</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>neg</th>\n",
       "      <td>233.6754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pos</th>\n",
       "      <td>237.8132</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       review_wordcount\n",
       "label                  \n",
       "neg            233.6754\n",
       "pos            237.8132"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mean_length_df = review_length_df.groupby('label').mean()\n",
    "\n",
    "display(mean_length_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average word count for negative reviews: 234.0\n",
      "Average word count for positive reviews: 238.0\n"
     ]
    }
   ],
   "source": [
    "neg_wc_avg = round(mean_length_df.at['neg', 'review_wordcount'], 0)\n",
    "pos_wc_avg = round(mean_length_df.at['pos', 'review_wordcount'], 0)\n",
    "\n",
    "print(f'Average word count for negative reviews: {neg_wc_avg}')\n",
    "print(f'Average word count for positive reviews: {pos_wc_avg}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e72262f36389dfd86f56c252845ddbdd",
     "grade": true,
     "grade_id": "cell-4e4215014acc2d2e",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# check that the variable exists\n",
    "assert 'neg_wc_avg' in globals(\n",
    "), \"Please make sure that your solution is named 'neg_wc_avg'\"\n",
    "\n",
    "# This test has been intentionally hidden. It will be up to you to decide if your solution\n",
    "# is sufficiently good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "29f3019b4ecef97d60dab3561c735937",
     "grade": true,
     "grade_id": "cell-dfdf48541df7774c",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_1_5_2(pos_wc_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.6** <br> {points: 2}  \n",
    "\n",
    "Plot the average review wordcount per label in a bar chart. \n",
    "\n",
    "Save the plot in an object named `plot_avg_wc`.\n",
    "\n",
    "Remember to provide a title to your plot as well.\n",
    "\n",
    "*Hint: remember you can plot `groupby` objects and when you do so, you'll need to reset your index.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1110148e238db09fb436e03e03ec2aca",
     "grade": false,
     "grade_id": "cell-70cb229b2af4e588",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-27a4d3ce50344fb7a285d27412c44841\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-27a4d3ce50344fb7a285d27412c44841\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-27a4d3ce50344fb7a285d27412c44841\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.8.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function loadScript(lib) {\n",
       "      return new Promise(function(resolve, reject) {\n",
       "        var s = document.createElement('script');\n",
       "        s.src = paths[lib];\n",
       "        s.async = true;\n",
       "        s.onload = () => resolve(paths[lib]);\n",
       "        s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "        document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "      });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else if (typeof vegaEmbed === \"function\") {\n",
       "      displayChart(vegaEmbed);\n",
       "    } else {\n",
       "      loadScript(\"vega\")\n",
       "        .then(() => loadScript(\"vega-lite\"))\n",
       "        .then(() => loadScript(\"vega-embed\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}, \"axis\": {\"labelFontSize\": 12, \"titleFontSize\": 15}}, \"data\": {\"name\": \"data-dc2bd0aa4a626915603d909710a0041b\"}, \"mark\": \"bar\", \"encoding\": {\"color\": {\"type\": \"nominal\", \"field\": \"label\", \"title\": \"Review Label\"}, \"x\": {\"type\": \"nominal\", \"field\": \"label\", \"title\": \"Review Label\"}, \"y\": {\"type\": \"quantitative\", \"field\": \"review_wordcount\", \"scale\": {\"domain\": [223.6754, 247.8132]}, \"title\": \"Average Word Count\"}}, \"height\": 450, \"title\": {\"text\": \"Average Word Count by Review Label\", \"anchor\": \"middle\", \"fontSize\": 20}, \"width\": 300, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.8.1.json\", \"datasets\": {\"data-dc2bd0aa4a626915603d909710a0041b\": [{\"label\": \"neg\", \"review_wordcount\": 233.6754}, {\"label\": \"pos\", \"review_wordcount\": 237.8132}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_avg_wc = alt.Chart(mean_length_df.reset_index()).mark_bar().encode(\n",
    "    x = alt.X(shorthand = 'label', title = 'Review Label'),\n",
    "    y = alt.Y(\n",
    "        shorthand = 'review_wordcount', \n",
    "        title = 'Average Word Count', \n",
    "        scale = alt.Scale(domain = [mean_length_df['review_wordcount'].min() - 10, mean_length_df['review_wordcount'].max() + 10])\n",
    "    ),\n",
    "    color = alt.Color('label', title = 'Review Label')\n",
    ").properties(\n",
    "    title = alt.TitleParams(\n",
    "        text = 'Average Word Count by Review Label',\n",
    "        fontSize = 20,\n",
    "        anchor = 'middle'\n",
    "    ),\n",
    "    width = 300, height = 450\n",
    ").configure_axis(\n",
    "    titleFontSize = 15, labelFontSize = 12\n",
    ")\n",
    "\n",
    "display(plot_avg_wc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fe854b84fbd3713378248aeee52cbed5",
     "grade": true,
     "grade_id": "cell-d15d6ded8ce42ef9",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_1_6(plot_avg_wc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.7** <br> {points: 1}  \n",
    "\n",
    "Let's make a baseline model using `DummyClassifier`.\n",
    "\n",
    "Build a `DummyClassifier` named `dummy` using `strategy='most_frequent'`. Perform cross-validation on the training portion. Make sure that you return the training score using `return_train_score=True`. \n",
    "\n",
    "Save the results in a dataframe named `dummy_scores`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1fcd19a7d929b20d476a50130b92d4dd",
     "grade": false,
     "grade_id": "cell-21468e80688065c5",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.004955</td>\n",
       "      <td>0.004044</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.004331</td>\n",
       "      <td>0.003998</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.004145</td>\n",
       "      <td>0.004037</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.004138</td>\n",
       "      <td>0.004088</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.003999</td>\n",
       "      <td>0.004016</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_score  train_score\n",
       "0  0.004955    0.004044         0.5          0.5\n",
       "1  0.004331    0.003998         0.5          0.5\n",
       "2  0.004145    0.004037         0.5          0.5\n",
       "3  0.004138    0.004088         0.5          0.5\n",
       "4  0.003999    0.004016         0.5          0.5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dummy = DummyClassifier(strategy = 'most_frequent')\n",
    "\n",
    "dummy_scores = pd.DataFrame(cross_validate(\n",
    "        estimator = dummy, \n",
    "        X = X_train, y = y_train, \n",
    "        cv = 5, return_train_score = True\n",
    "    )\n",
    ")\n",
    "\n",
    "display(dummy_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a01f0f9b2e76ca787f247a51e6df471d",
     "grade": true,
     "grade_id": "cell-3ae4f9a2e6cc1453",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_1_7(dummy_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.8** <br> {points: 0}\n",
    "\n",
    "Import `CountVectorizer` and `LogisticRegression`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1b942243d97b0ab0b1975ed832e9d68c",
     "grade": false,
     "grade_id": "cell-bb57d43dab2cdbf5",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c39a7ac636cf6caa2840a5fe532e2bee",
     "grade": true,
     "grade_id": "cell-884574d9f3ed3195",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_1_8()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.9** <br> {points: 1}  \n",
    "\n",
    "Build a pipeline named `lr_pipe` that uses the `CountVectorizer()` transformer followed by the logistic regression model (set `max_iter=2000` this will help avoid any warnings).\n",
    "\n",
    "Perform 5 fold cross-validation on the training set using `lr_pipe` and return the training score. Save the results in a dataframe named `lr_scores`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4bf8bd17a8cc7af7cfe278d76a916c14",
     "grade": false,
     "grade_id": "cell-5f01df846f98b34f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.897073</td>\n",
       "      <td>0.390073</td>\n",
       "      <td>0.7180</td>\n",
       "      <td>0.741250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.863648</td>\n",
       "      <td>0.388414</td>\n",
       "      <td>0.7235</td>\n",
       "      <td>0.738000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.897852</td>\n",
       "      <td>0.395840</td>\n",
       "      <td>0.7275</td>\n",
       "      <td>0.741250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.858708</td>\n",
       "      <td>0.382902</td>\n",
       "      <td>0.7320</td>\n",
       "      <td>0.735625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.883700</td>\n",
       "      <td>0.389112</td>\n",
       "      <td>0.7300</td>\n",
       "      <td>0.736875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_score  train_score\n",
       "0  1.897073    0.390073      0.7180     0.741250\n",
       "1  1.863648    0.388414      0.7235     0.738000\n",
       "2  1.897852    0.395840      0.7275     0.741250\n",
       "3  1.858708    0.382902      0.7320     0.735625\n",
       "4  1.883700    0.389112      0.7300     0.736875"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr_pipe = make_pipeline(\n",
    "    CountVectorizer(max_features = 100),\n",
    "    LogisticRegression(max_iter = 2000)\n",
    ")\n",
    "\n",
    "lr_scores = pd.DataFrame(\n",
    "    cross_validate(\n",
    "        estimator = lr_pipe,\n",
    "        X = X_train, y = y_train,\n",
    "        cv = 5, return_train_score = True,\n",
    "        n_jobs = -1\n",
    "    )\n",
    ")\n",
    "\n",
    "display(lr_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6fd5d3aa00d2db3f30b56180bd95da74",
     "grade": true,
     "grade_id": "cell-62e4194474333507",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_1_9(lr_pipe,lr_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.10** <br> {points: 1} \n",
    "\n",
    "What is the mean of each column in `lr_scores`?\n",
    "\n",
    "Save your result in an object named `lr_mean`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d765dba1dd19717ec97ff364b57e3afb",
     "grade": false,
     "grade_id": "cell-49d3f6f99089b4dd",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fit_time       1.880196\n",
       "score_time     0.389268\n",
       "test_score     0.726200\n",
       "train_score    0.738600\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr_mean = lr_scores.mean()\n",
    "\n",
    "display(lr_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "71195c46fee15811c051238cb50780da",
     "grade": true,
     "grade_id": "cell-21515470d3758502",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_1_10(lr_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.11** <br> {points: 1}  \n",
    "\n",
    "Which model performs better? \n",
    "\n",
    "A) `DummyClassifier`\n",
    "\n",
    "B) `LogisticRegression`\n",
    "\n",
    "*Answer in the cell below using the uppercase letter associated with your answer. Place your answer between `\"\"`, assign the correct answer to an object called `answer1_11`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6797f61eb1d1c2c0b417316607d7cd92",
     "grade": false,
     "grade_id": "cell-ac18a6619cc03429",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer 1.11 : B\n"
     ]
    }
   ],
   "source": [
    "if (lr_mean['test_score'] < dummy_scores.mean()['test_score']) :\n",
    "    answer1_11 = 'A'\n",
    "else :\n",
    "    answer1_11 = 'B'\n",
    "\n",
    "print(f'Answer 1.11 : {answer1_11}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "826a6045acae93adb7f33299782e6a31",
     "grade": true,
     "grade_id": "cell-5e08f691bef0f241",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_1_11(answer1_11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.12** <br> {points: 2} \n",
    "\n",
    "Let's see if we can optimize our model by hyperparameter tuning both `max_features` and `C`. \n",
    "\n",
    "First, let's answer the following questions. \n",
    "\n",
    "i) Does `max_features` correspond to a hyperparameter for `CountVectorizer` or `LogisticRegression`? Answer the name in an object named `max_f_hyper`.\n",
    "\n",
    "ii) Does `C` correspond to a hyperparameter for `CountVectorizer` or `LogisticRegression`? Answer the name in an object named `C_hyper`.\n",
    "\n",
    "*Answer in the cell below by specifying either \"CountVectorizer\" or \"LogisticRegression\" for the objects named in the above question. Make sure your answer is between `\"\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9607196a820e6a9d37418065019cb3f9",
     "grade": false,
     "grade_id": "cell-509fe358c804db31",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "max_f_hyper = 'CountVectorizer' \n",
    "C_hyper = 'LogisticRegression'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c1306d02d02830248312a2b558fcc555",
     "grade": true,
     "grade_id": "cell-f78d6830b977e12e",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_1_12_1(max_f_hyper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d2641f5933dc0f6ff8f0b2576b120c50",
     "grade": true,
     "grade_id": "cell-f9d746773a3b8e2a",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_1_12_2(C_hyper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.13** <br> {points: 1} \n",
    "\n",
    "If we increase the `C` hyperparameter values, is that more likely to result in a model that is overfitted or underfitted? \n",
    "\n",
    "*Answer in the cell below by specifying either \"overfitted\" or \"underfitted\" in an object named `answer_1_13`. Make sure your answer is between `\"\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b7bd2746e0bdc65fd62d3cf9f7e2b7ed",
     "grade": false,
     "grade_id": "cell-796d393b70bee261",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "answer_1_13 = 'overfitted'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cbaf48c17bdc01aeee23b8f878c0da41",
     "grade": true,
     "grade_id": "cell-9b51ac5ffe66192f",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_1_13(answer_1_13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.14** <br> {points: 1}\n",
    "\n",
    "The time has come to hyperparameter tune! Define a pipeline with `CountVectorizer` and `LogisticRegression` with `max_iter=1000`. Name the pipeline `main_pipe`. \n",
    "\n",
    "Use `RandomizedSearchCV` to jointly optimize the hyperparameters in the `params_grid` that we have provided for you. \n",
    "Name this object `random_search`. Specify `n_iter=10`, `cv=5`, `random_state=888`, `n_jobs=-1`, `verbose=3`, and `return_train_score=True`. \n",
    "Make sure to fit your model on the training portion of the IMDB dataset. \n",
    "\n",
    "This can take quite a while (10 minutes for me!) so please be patient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"logisticregression__C\" : loguniform(0.01, 100),\n",
    "    \"countvectorizer__max_features\" : randint(10, 1000),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b9b813ddc61ba79584347ff625b0060c",
     "grade": false,
     "grade_id": "cell-84e687666b1a490f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV 1/5] END countvectorizer__max_features=520, logisticregression__C=3.127595166460435;, score=(train=0.858, test=0.818) total time=   3.1s\n",
      "[CV 2/5] END countvectorizer__max_features=520, logisticregression__C=3.127595166460435;, score=(train=0.861, test=0.815) total time=   3.0s\n",
      "[CV 3/5] END countvectorizer__max_features=520, logisticregression__C=3.127595166460435;, score=(train=0.862, test=0.818) total time=   2.9s\n",
      "[CV 4/5] END countvectorizer__max_features=520, logisticregression__C=3.127595166460435;, score=(train=0.862, test=0.822) total time=   2.8s\n",
      "[CV 5/5] END countvectorizer__max_features=520, logisticregression__C=3.127595166460435;, score=(train=0.856, test=0.836) total time=   3.1s\n",
      "[CV 1/5] END countvectorizer__max_features=249, logisticregression__C=0.8588233360393741;, score=(train=0.806, test=0.775) total time=   2.7s\n",
      "[CV 2/5] END countvectorizer__max_features=249, logisticregression__C=0.8588233360393741;, score=(train=0.807, test=0.784) total time=   2.5s\n",
      "[CV 3/5] END countvectorizer__max_features=249, logisticregression__C=0.8588233360393741;, score=(train=0.805, test=0.790) total time=   2.5s\n",
      "[CV 4/5] END countvectorizer__max_features=249, logisticregression__C=0.8588233360393741;, score=(train=0.805, test=0.789) total time=   2.5s\n",
      "[CV 5/5] END countvectorizer__max_features=249, logisticregression__C=0.8588233360393741;, score=(train=0.801, test=0.797) total time=   2.5s\n",
      "[CV 1/5] END countvectorizer__max_features=369, logisticregression__C=0.024075609796438913;, score=(train=0.831, test=0.797) total time=   2.4s\n",
      "[CV 2/5] END countvectorizer__max_features=369, logisticregression__C=0.024075609796438913;, score=(train=0.827, test=0.808) total time=   2.5s\n",
      "[CV 3/5] END countvectorizer__max_features=369, logisticregression__C=0.024075609796438913;, score=(train=0.831, test=0.818) total time=   2.5s\n",
      "[CV 4/5] END countvectorizer__max_features=369, logisticregression__C=0.024075609796438913;, score=(train=0.829, test=0.805) total time=   2.5s\n",
      "[CV 5/5] END countvectorizer__max_features=369, logisticregression__C=0.024075609796438913;, score=(train=0.824, test=0.820) total time=   2.5s\n",
      "[CV 1/5] END countvectorizer__max_features=710, logisticregression__C=0.016976195590890333;, score=(train=0.867, test=0.831) total time=   2.6s\n",
      "[CV 2/5] END countvectorizer__max_features=710, logisticregression__C=0.016976195590890333;, score=(train=0.865, test=0.838) total time=   2.5s\n",
      "[CV 3/5] END countvectorizer__max_features=710, logisticregression__C=0.016976195590890333;, score=(train=0.865, test=0.832) total time=   2.6s\n",
      "[CV 4/5] END countvectorizer__max_features=710, logisticregression__C=0.016976195590890333;, score=(train=0.863, test=0.832) total time=   2.5s\n",
      "[CV 5/5] END countvectorizer__max_features=710, logisticregression__C=0.016976195590890333;, score=(train=0.864, test=0.847) total time=   2.5s\n",
      "[CV 1/5] END countvectorizer__max_features=410, logisticregression__C=0.08489093942377351;, score=(train=0.845, test=0.819) total time=   2.8s\n",
      "[CV 2/5] END countvectorizer__max_features=410, logisticregression__C=0.08489093942377351;, score=(train=0.841, test=0.808) total time=   2.7s\n",
      "[CV 3/5] END countvectorizer__max_features=410, logisticregression__C=0.08489093942377351;, score=(train=0.840, test=0.823) total time=   2.6s\n",
      "[CV 4/5] END countvectorizer__max_features=410, logisticregression__C=0.08489093942377351;, score=(train=0.841, test=0.815) total time=   2.5s\n",
      "[CV 5/5] END countvectorizer__max_features=410, logisticregression__C=0.08489093942377351;, score=(train=0.836, test=0.822) total time=   2.6s\n",
      "[CV 1/5] END countvectorizer__max_features=874, logisticregression__C=0.03402603563390611;, score=(train=0.882, test=0.844) total time=   2.7s\n",
      "[CV 2/5] END countvectorizer__max_features=874, logisticregression__C=0.03402603563390611;, score=(train=0.884, test=0.849) total time=   2.9s\n",
      "[CV 3/5] END countvectorizer__max_features=874, logisticregression__C=0.03402603563390611;, score=(train=0.885, test=0.847) total time=   2.7s\n",
      "[CV 4/5] END countvectorizer__max_features=874, logisticregression__C=0.03402603563390611;, score=(train=0.884, test=0.849) total time=   2.7s\n",
      "[CV 5/5] END countvectorizer__max_features=874, logisticregression__C=0.03402603563390611;, score=(train=0.884, test=0.846) total time=   2.7s\n",
      "[CV 1/5] END countvectorizer__max_features=986, logisticregression__C=8.01031006424307;, score=(train=0.901, test=0.833) total time=   4.1s\n",
      "[CV 2/5] END countvectorizer__max_features=986, logisticregression__C=8.01031006424307;, score=(train=0.905, test=0.826) total time=   5.0s\n",
      "[CV 3/5] END countvectorizer__max_features=986, logisticregression__C=8.01031006424307;, score=(train=0.904, test=0.832) total time=   4.7s\n",
      "[CV 4/5] END countvectorizer__max_features=986, logisticregression__C=8.01031006424307;, score=(train=0.902, test=0.833) total time=   5.2s\n",
      "[CV 5/5] END countvectorizer__max_features=986, logisticregression__C=8.01031006424307;, score=(train=0.904, test=0.831) total time=   4.9s\n",
      "[CV 1/5] END countvectorizer__max_features=413, logisticregression__C=0.09850535344353391;, score=(train=0.845, test=0.815) total time=   2.5s\n",
      "[CV 2/5] END countvectorizer__max_features=413, logisticregression__C=0.09850535344353391;, score=(train=0.842, test=0.809) total time=   2.6s\n",
      "[CV 3/5] END countvectorizer__max_features=413, logisticregression__C=0.09850535344353391;, score=(train=0.840, test=0.826) total time=   2.6s\n",
      "[CV 4/5] END countvectorizer__max_features=413, logisticregression__C=0.09850535344353391;, score=(train=0.840, test=0.816) total time=   2.6s\n",
      "[CV 5/5] END countvectorizer__max_features=413, logisticregression__C=0.09850535344353391;, score=(train=0.838, test=0.819) total time=   2.6s\n",
      "[CV 1/5] END countvectorizer__max_features=824, logisticregression__C=0.020389214792861758;, score=(train=0.875, test=0.842) total time=   2.6s\n",
      "[CV 2/5] END countvectorizer__max_features=824, logisticregression__C=0.020389214792861758;, score=(train=0.876, test=0.841) total time=   3.0s\n",
      "[CV 3/5] END countvectorizer__max_features=824, logisticregression__C=0.020389214792861758;, score=(train=0.877, test=0.840) total time=   2.8s\n",
      "[CV 4/5] END countvectorizer__max_features=824, logisticregression__C=0.020389214792861758;, score=(train=0.875, test=0.842) total time=   2.6s\n",
      "[CV 5/5] END countvectorizer__max_features=824, logisticregression__C=0.020389214792861758;, score=(train=0.876, test=0.848) total time=   2.6s\n",
      "[CV 1/5] END countvectorizer__max_features=190, logisticregression__C=31.38036417480889;, score=(train=0.777, test=0.751) total time=   2.4s\n",
      "[CV 2/5] END countvectorizer__max_features=190, logisticregression__C=31.38036417480889;, score=(train=0.782, test=0.765) total time=   2.5s\n",
      "[CV 3/5] END countvectorizer__max_features=190, logisticregression__C=31.38036417480889;, score=(train=0.775, test=0.769) total time=   2.3s\n",
      "[CV 4/5] END countvectorizer__max_features=190, logisticregression__C=31.38036417480889;, score=(train=0.780, test=0.768) total time=   2.3s\n",
      "[CV 5/5] END countvectorizer__max_features=190, logisticregression__C=31.38036417480889;, score=(train=0.776, test=0.767) total time=   2.3s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=Pipeline(steps=[('countvectorizer',\n",
       "                                              CountVectorizer()),\n",
       "                                             ('logisticregression',\n",
       "                                              LogisticRegression(max_iter=1000))]),\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'countvectorizer__max_features': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f6712abb940>,\n",
       "                                        'logisticregression__C': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f6709d03430>},\n",
       "                   random_state=888, return_train_score=True, verbose=3)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "main_pipe = make_pipeline(\n",
    "    CountVectorizer(),\n",
    "    LogisticRegression(max_iter = 1000),\n",
    ")\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator = main_pipe,\n",
    "    param_distributions = param_grid,\n",
    "    n_iter = 10, cv = 5,\n",
    "    random_state = 888,\n",
    "    n_jobs = -1, verbose = 3,\n",
    "    return_train_score = True\n",
    ").fit(X_train, y_train)\n",
    "\n",
    "display(random_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_countvectorizer__max_features</th>\n",
       "      <th>param_logisticregression__C</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.584242</td>\n",
       "      <td>0.137288</td>\n",
       "      <td>0.414497</td>\n",
       "      <td>0.004990</td>\n",
       "      <td>520</td>\n",
       "      <td>3.127595</td>\n",
       "      <td>{'countvectorizer__max_features': 520, 'logist...</td>\n",
       "      <td>0.8175</td>\n",
       "      <td>0.8145</td>\n",
       "      <td>0.8175</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8214</td>\n",
       "      <td>0.007632</td>\n",
       "      <td>5</td>\n",
       "      <td>0.858125</td>\n",
       "      <td>0.860625</td>\n",
       "      <td>0.861500</td>\n",
       "      <td>0.861750</td>\n",
       "      <td>0.856250</td>\n",
       "      <td>0.859650</td>\n",
       "      <td>0.002129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.138309</td>\n",
       "      <td>0.077506</td>\n",
       "      <td>0.393721</td>\n",
       "      <td>0.004447</td>\n",
       "      <td>249</td>\n",
       "      <td>0.858823</td>\n",
       "      <td>{'countvectorizer__max_features': 249, 'logist...</td>\n",
       "      <td>0.7755</td>\n",
       "      <td>0.7845</td>\n",
       "      <td>0.7900</td>\n",
       "      <td>...</td>\n",
       "      <td>0.7872</td>\n",
       "      <td>0.007089</td>\n",
       "      <td>9</td>\n",
       "      <td>0.805625</td>\n",
       "      <td>0.807250</td>\n",
       "      <td>0.805000</td>\n",
       "      <td>0.805125</td>\n",
       "      <td>0.800625</td>\n",
       "      <td>0.804725</td>\n",
       "      <td>0.002201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.059432</td>\n",
       "      <td>0.033133</td>\n",
       "      <td>0.405629</td>\n",
       "      <td>0.005041</td>\n",
       "      <td>369</td>\n",
       "      <td>0.024076</td>\n",
       "      <td>{'countvectorizer__max_features': 369, 'logist...</td>\n",
       "      <td>0.7975</td>\n",
       "      <td>0.8085</td>\n",
       "      <td>0.8175</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8097</td>\n",
       "      <td>0.008060</td>\n",
       "      <td>8</td>\n",
       "      <td>0.831250</td>\n",
       "      <td>0.826625</td>\n",
       "      <td>0.831000</td>\n",
       "      <td>0.829375</td>\n",
       "      <td>0.824250</td>\n",
       "      <td>0.828500</td>\n",
       "      <td>0.002689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.112527</td>\n",
       "      <td>0.060521</td>\n",
       "      <td>0.418619</td>\n",
       "      <td>0.004398</td>\n",
       "      <td>710</td>\n",
       "      <td>0.016976</td>\n",
       "      <td>{'countvectorizer__max_features': 710, 'logist...</td>\n",
       "      <td>0.8310</td>\n",
       "      <td>0.8380</td>\n",
       "      <td>0.8320</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8358</td>\n",
       "      <td>0.005921</td>\n",
       "      <td>3</td>\n",
       "      <td>0.867000</td>\n",
       "      <td>0.864500</td>\n",
       "      <td>0.865250</td>\n",
       "      <td>0.863375</td>\n",
       "      <td>0.863750</td>\n",
       "      <td>0.864775</td>\n",
       "      <td>0.001285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.227695</td>\n",
       "      <td>0.089340</td>\n",
       "      <td>0.406735</td>\n",
       "      <td>0.002795</td>\n",
       "      <td>410</td>\n",
       "      <td>0.084891</td>\n",
       "      <td>{'countvectorizer__max_features': 410, 'logist...</td>\n",
       "      <td>0.8190</td>\n",
       "      <td>0.8085</td>\n",
       "      <td>0.8225</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8172</td>\n",
       "      <td>0.005154</td>\n",
       "      <td>6</td>\n",
       "      <td>0.845125</td>\n",
       "      <td>0.841000</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>0.840750</td>\n",
       "      <td>0.835875</td>\n",
       "      <td>0.840550</td>\n",
       "      <td>0.002944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.311941</td>\n",
       "      <td>0.087218</td>\n",
       "      <td>0.420923</td>\n",
       "      <td>0.005311</td>\n",
       "      <td>874</td>\n",
       "      <td>0.034026</td>\n",
       "      <td>{'countvectorizer__max_features': 874, 'logist...</td>\n",
       "      <td>0.8440</td>\n",
       "      <td>0.8485</td>\n",
       "      <td>0.8470</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8468</td>\n",
       "      <td>0.001860</td>\n",
       "      <td>1</td>\n",
       "      <td>0.882125</td>\n",
       "      <td>0.883875</td>\n",
       "      <td>0.884625</td>\n",
       "      <td>0.883750</td>\n",
       "      <td>0.883875</td>\n",
       "      <td>0.883650</td>\n",
       "      <td>0.000823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.373017</td>\n",
       "      <td>0.364055</td>\n",
       "      <td>0.421649</td>\n",
       "      <td>0.005422</td>\n",
       "      <td>986</td>\n",
       "      <td>8.01031</td>\n",
       "      <td>{'countvectorizer__max_features': 986, 'logist...</td>\n",
       "      <td>0.8330</td>\n",
       "      <td>0.8255</td>\n",
       "      <td>0.8315</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8308</td>\n",
       "      <td>0.002768</td>\n",
       "      <td>4</td>\n",
       "      <td>0.901500</td>\n",
       "      <td>0.904750</td>\n",
       "      <td>0.904000</td>\n",
       "      <td>0.901875</td>\n",
       "      <td>0.903750</td>\n",
       "      <td>0.903175</td>\n",
       "      <td>0.001264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.162653</td>\n",
       "      <td>0.027485</td>\n",
       "      <td>0.408516</td>\n",
       "      <td>0.005270</td>\n",
       "      <td>413</td>\n",
       "      <td>0.098505</td>\n",
       "      <td>{'countvectorizer__max_features': 413, 'logist...</td>\n",
       "      <td>0.8145</td>\n",
       "      <td>0.8095</td>\n",
       "      <td>0.8255</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8168</td>\n",
       "      <td>0.005250</td>\n",
       "      <td>7</td>\n",
       "      <td>0.845000</td>\n",
       "      <td>0.841625</td>\n",
       "      <td>0.839750</td>\n",
       "      <td>0.840375</td>\n",
       "      <td>0.838000</td>\n",
       "      <td>0.840950</td>\n",
       "      <td>0.002338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.288573</td>\n",
       "      <td>0.143564</td>\n",
       "      <td>0.421583</td>\n",
       "      <td>0.005680</td>\n",
       "      <td>824</td>\n",
       "      <td>0.020389</td>\n",
       "      <td>{'countvectorizer__max_features': 824, 'logist...</td>\n",
       "      <td>0.8420</td>\n",
       "      <td>0.8410</td>\n",
       "      <td>0.8400</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8425</td>\n",
       "      <td>0.002608</td>\n",
       "      <td>2</td>\n",
       "      <td>0.875375</td>\n",
       "      <td>0.875750</td>\n",
       "      <td>0.877250</td>\n",
       "      <td>0.875125</td>\n",
       "      <td>0.876125</td>\n",
       "      <td>0.875925</td>\n",
       "      <td>0.000744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.975807</td>\n",
       "      <td>0.071436</td>\n",
       "      <td>0.392318</td>\n",
       "      <td>0.004677</td>\n",
       "      <td>190</td>\n",
       "      <td>31.380364</td>\n",
       "      <td>{'countvectorizer__max_features': 190, 'logist...</td>\n",
       "      <td>0.7510</td>\n",
       "      <td>0.7655</td>\n",
       "      <td>0.7690</td>\n",
       "      <td>...</td>\n",
       "      <td>0.7641</td>\n",
       "      <td>0.006651</td>\n",
       "      <td>10</td>\n",
       "      <td>0.777500</td>\n",
       "      <td>0.782250</td>\n",
       "      <td>0.775250</td>\n",
       "      <td>0.779750</td>\n",
       "      <td>0.776375</td>\n",
       "      <td>0.778225</td>\n",
       "      <td>0.002503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       2.584242      0.137288         0.414497        0.004990   \n",
       "1       2.138309      0.077506         0.393721        0.004447   \n",
       "2       2.059432      0.033133         0.405629        0.005041   \n",
       "3       2.112527      0.060521         0.418619        0.004398   \n",
       "4       2.227695      0.089340         0.406735        0.002795   \n",
       "5       2.311941      0.087218         0.420923        0.005311   \n",
       "6       4.373017      0.364055         0.421649        0.005422   \n",
       "7       2.162653      0.027485         0.408516        0.005270   \n",
       "8       2.288573      0.143564         0.421583        0.005680   \n",
       "9       1.975807      0.071436         0.392318        0.004677   \n",
       "\n",
       "  param_countvectorizer__max_features param_logisticregression__C  \\\n",
       "0                                 520                    3.127595   \n",
       "1                                 249                    0.858823   \n",
       "2                                 369                    0.024076   \n",
       "3                                 710                    0.016976   \n",
       "4                                 410                    0.084891   \n",
       "5                                 874                    0.034026   \n",
       "6                                 986                     8.01031   \n",
       "7                                 413                    0.098505   \n",
       "8                                 824                    0.020389   \n",
       "9                                 190                   31.380364   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0  {'countvectorizer__max_features': 520, 'logist...             0.8175   \n",
       "1  {'countvectorizer__max_features': 249, 'logist...             0.7755   \n",
       "2  {'countvectorizer__max_features': 369, 'logist...             0.7975   \n",
       "3  {'countvectorizer__max_features': 710, 'logist...             0.8310   \n",
       "4  {'countvectorizer__max_features': 410, 'logist...             0.8190   \n",
       "5  {'countvectorizer__max_features': 874, 'logist...             0.8440   \n",
       "6  {'countvectorizer__max_features': 986, 'logist...             0.8330   \n",
       "7  {'countvectorizer__max_features': 413, 'logist...             0.8145   \n",
       "8  {'countvectorizer__max_features': 824, 'logist...             0.8420   \n",
       "9  {'countvectorizer__max_features': 190, 'logist...             0.7510   \n",
       "\n",
       "   split1_test_score  split2_test_score  ...  mean_test_score  std_test_score  \\\n",
       "0             0.8145             0.8175  ...           0.8214        0.007632   \n",
       "1             0.7845             0.7900  ...           0.7872        0.007089   \n",
       "2             0.8085             0.8175  ...           0.8097        0.008060   \n",
       "3             0.8380             0.8320  ...           0.8358        0.005921   \n",
       "4             0.8085             0.8225  ...           0.8172        0.005154   \n",
       "5             0.8485             0.8470  ...           0.8468        0.001860   \n",
       "6             0.8255             0.8315  ...           0.8308        0.002768   \n",
       "7             0.8095             0.8255  ...           0.8168        0.005250   \n",
       "8             0.8410             0.8400  ...           0.8425        0.002608   \n",
       "9             0.7655             0.7690  ...           0.7641        0.006651   \n",
       "\n",
       "   rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0                5            0.858125            0.860625   \n",
       "1                9            0.805625            0.807250   \n",
       "2                8            0.831250            0.826625   \n",
       "3                3            0.867000            0.864500   \n",
       "4                6            0.845125            0.841000   \n",
       "5                1            0.882125            0.883875   \n",
       "6                4            0.901500            0.904750   \n",
       "7                7            0.845000            0.841625   \n",
       "8                2            0.875375            0.875750   \n",
       "9               10            0.777500            0.782250   \n",
       "\n",
       "   split2_train_score  split3_train_score  split4_train_score  \\\n",
       "0            0.861500            0.861750            0.856250   \n",
       "1            0.805000            0.805125            0.800625   \n",
       "2            0.831000            0.829375            0.824250   \n",
       "3            0.865250            0.863375            0.863750   \n",
       "4            0.840000            0.840750            0.835875   \n",
       "5            0.884625            0.883750            0.883875   \n",
       "6            0.904000            0.901875            0.903750   \n",
       "7            0.839750            0.840375            0.838000   \n",
       "8            0.877250            0.875125            0.876125   \n",
       "9            0.775250            0.779750            0.776375   \n",
       "\n",
       "   mean_train_score  std_train_score  \n",
       "0          0.859650         0.002129  \n",
       "1          0.804725         0.002201  \n",
       "2          0.828500         0.002689  \n",
       "3          0.864775         0.001285  \n",
       "4          0.840550         0.002944  \n",
       "5          0.883650         0.000823  \n",
       "6          0.903175         0.001264  \n",
       "7          0.840950         0.002338  \n",
       "8          0.875925         0.000744  \n",
       "9          0.778225         0.002503  \n",
       "\n",
       "[10 rows x 22 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cv_results = pd.DataFrame(random_search.cv_results_)\n",
    "\n",
    "display(cv_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ebfd094cc762d4759551bc33eb71422d",
     "grade": true,
     "grade_id": "cell-d3c5d0c38998206d",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_1_14(main_pipe,random_search)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.15** <br> {points: 3}\n",
    "\n",
    "What are the best hyperparameter values found by `RandomizedSearchCV` for `C` and `max_features`. Save it in an object named `optimal_parameters`. (The grader is expecting a dictionary object) \n",
    "\n",
    "What was the corresponding validation score? Save this in an object named `optimal_score`. \n",
    "\n",
    "*Hint: `.best_params_`  and `.best_score_` are helpful here.* \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "09af9afc61d82e0d5dcf5ad23d384ac4",
     "grade": false,
     "grade_id": "cell-bf31b1fe29c0d5fd",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Parameters : {'countvectorizer__max_features': 874, 'logisticregression__C': 0.03402603563390611}\n",
      "Optimal Score : 0.8468\n"
     ]
    }
   ],
   "source": [
    "optimal_parameters = random_search.best_params_\n",
    "optimal_score = random_search.best_score_\n",
    "\n",
    "print(f'Optimal Parameters : {optimal_parameters}')\n",
    "print(f'Optimal Score : {optimal_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "debb32e39a383f7342d843f3cc9f8bf8",
     "grade": true,
     "grade_id": "cell-b1dca3ab89397234",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# check that the variable exists\n",
    "assert 'optimal_parameters' in globals(\n",
    "), \"Please make sure that your solution is named 'optimal_parameters'\"\n",
    "\n",
    "# This test has been intentionally hidden. It will be up to you to decide if your solution\n",
    "# is sufficiently good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bef3101c07c3737412d8871e65cdf9ab",
     "grade": true,
     "grade_id": "cell-d4e6b241d1082f4f",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_1_15_2(random_search, optimal_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.16** <br> {points: 1}\n",
    "\n",
    "Are you getting a better mean validation score than logistic regression pipeline with default hyperparameters from 1.9? \n",
    "\n",
    "A) Yes\n",
    "\n",
    "B) No\n",
    "\n",
    "*Answer in the cell below using the uppercase letter associated with your answer. Place your answer between `\"\"`, assign the correct answer to an object called `answer1_16`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fb39e7d288c510b3078e16e638be70e6",
     "grade": false,
     "grade_id": "cell-29d75a60f3f9b0d6",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer 1.16 : A\n"
     ]
    }
   ],
   "source": [
    "if (optimal_score > lr_mean['test_score']) :\n",
    "    answer1_16 = 'A'\n",
    "else :\n",
    "    answer1_16 = 'B'\n",
    "\n",
    "print(f'Answer 1.16 : {answer1_16}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "447079e2e9d939b00b97909acf2ed2aa",
     "grade": true,
     "grade_id": "cell-6ad27d5574dc3a1d",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_1_16(answer1_16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Model Interpretation <a name=\"4\"></a>\n",
    "<hr>\n",
    "\n",
    "One of the primary advantages of linear models is their ability to interpret models in terms of important features. In this exercise, we'll explore the coefficients learned by logistic regression classifier. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.1** <br> {points: 1}\n",
    "\n",
    "Use `best_estimator_` to find the best estimator of `random_search` from 1.14 and save it in an object named `best_model`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c2b40b7a030f0f20f48ea47130d21b89",
     "grade": false,
     "grade_id": "cell-5406b2e78549d105",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('countvectorizer', CountVectorizer(max_features=874)),\n",
       "                ('logisticregression',\n",
       "                 LogisticRegression(C=0.03402603563390611, max_iter=1000))])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_model = random_search.best_estimator_\n",
    "\n",
    "display(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e1961c457fa94334b9d4b0009f249ce2",
     "grade": true,
     "grade_id": "cell-f539c53563023387",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_2_1(best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.2** <br> {points: 1}\n",
    "\n",
    "Use `coef_` to find the coefficients of the features. This information is exposed by the `coef_` attribute of [LogisticRegression](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) object. (*Hint: You'll have to reference `logisticregression` from the `best_model` object because `best_model` is a `Pipeline` object*.\n",
    "\n",
    "Name this object `lr_coeffs`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1d49bf838949ed888a7a1274b5fe5294",
     "grade": false,
     "grade_id": "cell-26b0b4fa95ef0621",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "lr_coeffs = best_model.named_steps['logisticregression'].coef_\n",
    "\n",
    "# display(lr_coeffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8d10989d0e50c9ebe8d18324d8c77b8f",
     "grade": true,
     "grade_id": "cell-37e4cd094699c2d1",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_2_2(lr_coeffs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.3** <br> {points: 1}\n",
    "\n",
    "Find the features that `CountVectorizer` produced by calling `get_feature_names()` on the `CountVectorizer` object within the `best_model` object. \n",
    "(*Hint: You'll have to reference `countvectorizer` from the `best_model` object because `best_model` is a `Pipeline` object*) \n",
    "\n",
    "Save this in an object named `vocab`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2981e966cc55e48545b0bf57fb4cac66",
     "grade": false,
     "grade_id": "cell-90314f78c1e949c7",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['10', '20', 'able', 'about', 'above', 'absolutely', 'across', 'act', 'acting', 'action', 'actor', 'actors', 'actress', 'actual', 'actually', 'add', 'after', 'again', 'against', 'age', 'ago', 'all', 'almost', 'alone', 'along', 'already', 'also', 'although', 'always', 'am', 'amazing', 'america', 'american', 'among', 'an', 'and', 'animation', 'annoying', 'another', 'any', 'anyone', 'anything', 'anyway', 'apparently', 'appears', 'are', 'aren', 'around', 'art', 'as', 'at', 'atmosphere', 'attempt', 'attention', 'audience', 'average', 'avoid', 'away', 'awful', 'baby', 'back', 'bad', 'based', 'basically', 'be', 'beautiful', 'beauty', 'became', 'because', 'become', 'becomes', 'been', 'before', 'beginning', 'begins', 'behind', 'being', 'believe', 'ben', 'best', 'better', 'between', 'beyond', 'big', 'bit', 'black', 'blood', 'body', 'book', 'boring', 'both', 'boy', 'br', 'brilliant', 'bring', 'brings', 'british', 'brother', 'brought', 'budget', 'bunch', 'but', 'buy', 'by', 'call', 'called', 'came', 'camera', 'can', 'cannot', 'car', 'care', 'career', 'case', 'cast', 'certain', 'certainly', 'chance', 'change', 'character', 'characters', 'cheap', 'check', 'child', 'children', 'christmas', 'cinema', 'cinematography', 'city', 'class', 'classic', 'clear', 'clearly', 'clichã', 'close', 'come', 'comedy', 'comes', 'comic', 'coming', 'comments', 'complete', 'completely', 'cool', 'could', 'couldn', 'country', 'couple', 'course', 'crap', 'crime', 'cut', 'dance', 'dark', 'daughter', 'david', 'day', 'days', 'de', 'dead', 'deal', 'death', 'decent', 'decided', 'definitely', 'despite', 'dialog', 'dialogue', 'did', 'didn', 'die', 'different', 'difficult', 'directed', 'direction', 'director', 'disappointed', 'disney', 'do', 'documentary', 'does', 'doesn', 'dog', 'doing', 'don', 'done', 'doubt', 'down', 'dr', 'drama', 'due', 'dull', 'during', 'dvd', 'each', 'early', 'earth', 'easily', 'easy', 'editing', 'effects', 'effort', 'either', 'elements', 'else', 'emotional', 'end', 'ending', 'ends', 'english', 'enjoy', 'enjoyable', 'enjoyed', 'enough', 'entertaining', 'entertainment', 'entire', 'episode', 'episodes', 'especially', 'etc', 'even', 'events', 'eventually', 'ever', 'every', 'everyone', 'everything', 'evil', 'exactly', 'example', 'excellent', 'except', 'expect', 'experience', 'extremely', 'eye', 'eyes', 'face', 'fact', 'fall', 'falls', 'family', 'famous', 'fan', 'fans', 'fantastic', 'fantasy', 'far', 'fast', 'father', 'favorite', 'feature', 'feel', 'feeling', 'feels', 'felt', 'female', 'few', 'fight', 'figure', 'film', 'filmed', 'films', 'final', 'finally', 'find', 'finds', 'fine', 'first', 'five', 'flick', 'follow', 'for', 'forget', 'form', 'found', 'four', 'free', 'french', 'friend', 'friends', 'from', 'full', 'fun', 'funny', 'future', 'game', 'gave', 'gay', 'general', 'genre', 'george', 'get', 'gets', 'getting', 'girl', 'girls', 'give', 'given', 'gives', 'giving', 'go', 'god', 'goes', 'going', 'gone', 'good', 'gore', 'got', 'great', 'greatest', 'group', 'guess', 'guy', 'guys', 'had', 'half', 'hand', 'happen', 'happened', 'happens', 'happy', 'hard', 'has', 'hate', 'have', 'haven', 'having', 'he', 'head', 'hear', 'heard', 'heart', 'hell', 'help', 'her', 'here', 'hero', 'herself', 'high', 'highly', 'hilarious', 'him', 'himself', 'his', 'history', 'hit', 'hollywood', 'home', 'hope', 'horrible', 'horror', 'hour', 'hours', 'house', 'how', 'however', 'huge', 'human', 'humor', 'husband', 'idea', 'if', 'imagine', 'important', 'in', 'including', 'indeed', 'instead', 'interest', 'interesting', 'into', 'involved', 'is', 'isn', 'it', 'its', 'itself', 'jack', 'james', 'jane', 'japanese', 'job', 'joe', 'john', 'jokes', 'just', 'keep', 'kid', 'kids', 'kill', 'killed', 'killer', 'killing', 'kind', 'king', 'knew', 'know', 'known', 'knows', 'lack', 'lady', 'lame', 'last', 'late', 'later', 'laugh', 'lead', 'leading', 'leads', 'learn', 'least', 'leave', 'left', 'less', 'let', 'level', 'life', 'light', 'like', 'liked', 'line', 'lines', 'little', 'live', 'lives', 'living', 'll', 'local', 'long', 'look', 'looked', 'looking', 'looks', 'lost', 'lot', 'lots', 'love', 'loved', 'low', 'made', 'main', 'major', 'make', 'makes', 'making', 'man', 'many', 'material', 'matter', 'may', 'maybe', 'me', 'mean', 'means', 'meets', 'memorable', 'men', 'mention', 'message', 'michael', 'middle', 'might', 'mind', 'minute', 'minutes', 'miss', 'modern', 'moment', 'moments', 'money', 'monster', 'more', 'most', 'mostly', 'mother', 'movie', 'movies', 'moving', 'mr', 'much', 'murder', 'music', 'musical', 'must', 'my', 'myself', 'mystery', 'name', 'named', 'near', 'nearly', 'need', 'needs', 'never', 'new', 'next', 'nice', 'night', 'no', 'non', 'none', 'nor', 'not', 'note', 'nothing', 'novel', 'now', 'number', 'obvious', 'obviously', 'of', 'off', 'often', 'oh', 'ok', 'okay', 'old', 'on', 'once', 'one', 'ones', 'only', 'open', 'opening', 'opinion', 'or', 'order', 'original', 'oscar', 'other', 'others', 'our', 'out', 'over', 'overall', 'own', 'parents', 'part', 'particular', 'particularly', 'parts', 'past', 'paul', 'people', 'perfect', 'performance', 'performances', 'perhaps', 'period', 'person', 'peter', 'picture', 'piece', 'place', 'play', 'played', 'playing', 'plays', 'please', 'plenty', 'plot', 'point', 'points', 'police', 'poor', 'poorly', 'possible', 'possibly', 'power', 'predictable', 'premise', 'present', 'pretty', 'probably', 'problem', 'problems', 'production', 'put', 'quality', 'quite', 'rather', 'rating', 're', 'read', 'reading', 'real', 'realistic', 'reality', 'realize', 'really', 'reason', 'recommend', 'red', 'relationship', 'release', 'released', 'remember', 'rest', 'review', 'reviews', 'richard', 'ridiculous', 'right', 'robert', 'rock', 'role', 'roles', 'romance', 'romantic', 'room', 'run', 'running', 'sad', 'said', 'same', 'save', 'saw', 'say', 'saying', 'says', 'scary', 'scene', 'scenes', 'school', 'sci', 'score', 'screen', 'screenplay', 'script', 'season', 'second', 'see', 'seeing', 'seem', 'seemed', 'seems', 'seen', 'self', 'sense', 'sequel', 'sequence', 'sequences', 'series', 'serious', 'seriously', 'set', 'sets', 'several', 'sex', 'sexual', 'shame', 'she', 'short', 'shot', 'shots', 'should', 'show', 'showing', 'shown', 'shows', 'side', 'silly', 'similar', 'simple', 'simply', 'since', 'single', 'sister', 'sit', 'situation', 'slow', 'small', 'so', 'some', 'somehow', 'someone', 'something', 'sometimes', 'somewhat', 'son', 'song', 'songs', 'soon', 'sorry', 'sort', 'sound', 'soundtrack', 'space', 'special', 'stand', 'star', 'stars', 'start', 'started', 'starts', 'stay', 'still', 'stop', 'stories', 'story', 'storyline', 'straight', 'strange', 'street', 'strong', 'stuff', 'stupid', 'style', 'subject', 'such', 'supporting', 'supposed', 'sure', 'surprise', 'surprised', 'suspense', 'take', 'taken', 'takes', 'taking', 'tale', 'talent', 'talk', 'talking', 'team', 'television', 'tell', 'tells', 'ten', 'terrible', 'than', 'that', 'the', 'theater', 'their', 'them', 'theme', 'themselves', 'then', 'there', 'these', 'they', 'thing', 'things', 'think', 'thinking', 'this', 'those', 'though', 'thought', 'three', 'thriller', 'through', 'throughout', 'time', 'times', 'title', 'to', 'today', 'together', 'told', 'tom', 'too', 'took', 'top', 'totally', 'town', 'tried', 'tries', 'true', 'truly', 'truth', 'try', 'trying', 'turn', 'turned', 'turns', 'tv', 'two', 'type', 'typical', 'under', 'understand', 'unfortunately', 'unless', 'until', 'up', 'upon', 'us', 'use', 'used', 'using', 'usual', 'usually', 've', 'version', 'very', 'video', 'view', 'viewer', 'viewers', 'viewing', 'violence', 'voice', 'wait', 'want', 'wanted', 'wants', 'war', 'was', 'wasn', 'waste', 'watch', 'watched', 'watching', 'way', 'ways', 'we', 'weak', 'well', 'went', 'were', 'what', 'whatever', 'when', 'where', 'whether', 'which', 'while', 'white', 'who', 'whole', 'whose', 'why', 'wife', 'will', 'wish', 'with', 'within', 'without', 'woman', 'women', 'won', 'wonder', 'wonderful', 'word', 'words', 'work', 'working', 'works', 'world', 'worse', 'worst', 'worth', 'would', 'wouldn', 'write', 'writer', 'writers', 'writing', 'written', 'wrong', 'year', 'years', 'yes', 'yet', 'york', 'you', 'young', 'your', 'yourself', 'zombie']\n"
     ]
    }
   ],
   "source": [
    "vocab = best_model.named_steps['countvectorizer'].get_feature_names()\n",
    "\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "de75e6cd5c9e776829d6574d695728aa",
     "grade": true,
     "grade_id": "cell-079308bed544da66",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_2_3(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've provided you the next code which combines the features with its respective feature coefficient (Our gift to you!) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>you</td>\n",
       "      <td>0.109271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>young</td>\n",
       "      <td>0.023149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>your</td>\n",
       "      <td>-0.032813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>yourself</td>\n",
       "      <td>-0.116746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>zombie</td>\n",
       "      <td>0.005472</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         word coefficient\n",
       "869       you    0.109271\n",
       "870     young    0.023149\n",
       "871      your   -0.032813\n",
       "872  yourself   -0.116746\n",
       "873    zombie    0.005472"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vocab_coef_df = pd.DataFrame(data = [vocab, lr_coeffs.flatten()]).T.rename(columns = {0 : 'word', 1 : 'coefficient'})\n",
    "\n",
    "display(vocab_coef_df.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.4** <br> {points: 1}\n",
    "\n",
    "Find the 10 words whose presence are most indicative of a positive review. Save the words and their corresponding weights in a dataframe ordered from most indicative to least indicative. \n",
    "\n",
    "Save these in a dataframe object named `positive_words`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "95070f19425f497be3bd79f73b7e55be",
     "grade": false,
     "grade_id": "cell-bf0a678aac774e18",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>excellent</td>\n",
       "      <td>0.675848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>846</th>\n",
       "      <td>wonderful</td>\n",
       "      <td>0.565064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>perfect</td>\n",
       "      <td>0.537209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>amazing</td>\n",
       "      <td>0.527257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>highly</td>\n",
       "      <td>0.47627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>favorite</td>\n",
       "      <td>0.475412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>loved</td>\n",
       "      <td>0.463348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>today</td>\n",
       "      <td>0.437116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>brilliant</td>\n",
       "      <td>0.42925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>great</td>\n",
       "      <td>0.416384</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          word coefficient\n",
       "231  excellent    0.675848\n",
       "846  wonderful    0.565064\n",
       "546    perfect    0.537209\n",
       "30     amazing    0.527257\n",
       "341     highly     0.47627\n",
       "251   favorite    0.475412\n",
       "439      loved    0.463348\n",
       "760      today    0.437116\n",
       "93   brilliant     0.42925\n",
       "310      great    0.416384"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "positive_words = vocab_coef_df.sort_values(by = 'coefficient', ascending = False).head(10)\n",
    "\n",
    "display(positive_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "67ada55b24d18cee7e8d91cdb028d308",
     "grade": true,
     "grade_id": "cell-27fcdeed004cd23d",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_2_4(positive_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.5** <br> {points: 1}\n",
    "\n",
    "Find the 10 words whose presence are most indicative of a negative review. Save the words and their corresponding weights in a dataframe ordered from most indicative to least indicative. \n",
    "\n",
    "Save these in a dataframe object named `negative_words`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "58a90462f5767bf71c868e02ac02fdf7",
     "grade": false,
     "grade_id": "cell-40bec17d8594e3be",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>854</th>\n",
       "      <td>worst</td>\n",
       "      <td>-1.066785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>awful</td>\n",
       "      <td>-0.768064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>813</th>\n",
       "      <td>waste</td>\n",
       "      <td>-0.745398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>horrible</td>\n",
       "      <td>-0.661008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>731</th>\n",
       "      <td>terrible</td>\n",
       "      <td>-0.660158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>poorly</td>\n",
       "      <td>-0.653296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>boring</td>\n",
       "      <td>-0.609551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>dull</td>\n",
       "      <td>-0.572556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>poor</td>\n",
       "      <td>-0.568203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>lame</td>\n",
       "      <td>-0.550497</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         word coefficient\n",
       "854     worst   -1.066785\n",
       "58      awful   -0.768064\n",
       "813     waste   -0.745398\n",
       "351  horrible   -0.661008\n",
       "731  terrible   -0.660158\n",
       "567    poorly   -0.653296\n",
       "89     boring   -0.609551\n",
       "191      dull   -0.572556\n",
       "566      poor   -0.568203\n",
       "403      lame   -0.550497"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "negative_words = vocab_coef_df.sort_values(by = 'coefficient', ascending = True).head(10)\n",
    "\n",
    "display(negative_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1f15dd097db11ce93c0525fcbf503d2c",
     "grade": true,
     "grade_id": "cell-ce053ef7af404102",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_2_5(negative_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.6** <br> {points: 2}\n",
    "\n",
    "Do the words associated with positive and negative reviews make sense? \n",
    "\n",
    "\n",
    "A) Yes\n",
    "\n",
    "B) No\n",
    "\n",
    "*Answer in the cell below using the uppercase letter associated with your answer. Place your answer between `\"\"`, assign the correct answer to an object called `answer2_6`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d8a6beb814d5eb831ba35a3c1a472d20",
     "grade": false,
     "grade_id": "cell-fec554d548d920e6",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "answer2_6 = 'A'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "06ee5ad91730b38f80584126e2e08fc1",
     "grade": true,
     "grade_id": "cell-ae39776298eb0871",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# check that the variable exists\n",
    "assert 'answer2_6' in globals(\n",
    "), \"Please make sure that your solution is named 'answer2_6'\"\n",
    "\n",
    "# This test has been intentionally hidden. It will be up to you to decide if your solution\n",
    "# is sufficiently good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.7** <br> {points: 1}\n",
    "\n",
    "Which of the following statements are true?\n",
    "\n",
    "i) It is useful to access the coefficient values since it helps us interpret the model to some extent.\n",
    "\n",
    "ii) The coefficients help humans to understand which features are the most relevant features for prediction and how they impact the prediction.\n",
    "\n",
    "iii) We can get feature importances for KNN by looking at the corresponding coefficients for each feature.\n",
    "\n",
    "iv) Decision Trees also have a manner of seeing which features are important by looking at the tree and where the splits occur. \n",
    "\n",
    "\n",
    "\n",
    "Select all that apply and add them into a list named `answer_2_7`. \n",
    "For example if statement i and iv are both true, your solution will look like this: \n",
    "\n",
    "```\n",
    "answer_2_7 = [\"i\", \"iv\"] \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fb0090d506991a99c9092df833b0fcc7",
     "grade": false,
     "grade_id": "cell-e123df6d5dee466d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "answer_2_7 = ['i', 'ii', 'iv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a113250e9e49d28d53e1ef72f915ba23",
     "grade": true,
     "grade_id": "cell-885d12270ba61d7b",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_2_7(answer_2_7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Test score, evaluation and `predict_proba`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.1** <br> {points: 1}\n",
    "\n",
    "Evaluate the best model from `random_search`  on the full training set.\n",
    "\n",
    "Save the score in an object named `training_score`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ab181575bc6745b369ba63317f50a797",
     "grade": false,
     "grade_id": "cell-d8c01ff13c8c4419",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score : 0.8833\n"
     ]
    }
   ],
   "source": [
    "training_score = random_search.score(X_train, y_train)\n",
    "\n",
    "print(f'Training Score : {training_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "310cd464111382abf62a0cb7a13eb05c",
     "grade": true,
     "grade_id": "cell-381e18a3118ff7ab",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_3_1(training_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.2** <br> {points: 2}\n",
    "\n",
    "Evaluate this model on the test set. \n",
    "\n",
    "Save the score in an object named `test_score`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "eb9f1c7f5f992011594cb3c42b46cb02",
     "grade": false,
     "grade_id": "cell-75684362301480a7",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score : 0.8479\n"
     ]
    }
   ],
   "source": [
    "test_score = random_search.score(X_test, y_test)\n",
    "\n",
    "print(f'Test Score : {test_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9677add0323b429f4ec5d94df03504de",
     "grade": true,
     "grade_id": "cell-30ab7efc7596ce70",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# check that the variable exists\n",
    "assert 'test_score' in globals(\n",
    "), \"Please make sure that your solution is named 'test_score'\"\n",
    "\n",
    "# This test has been intentionally hidden. It will be up to you to decide if your solution\n",
    "# is sufficiently good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.3** <br> {points: 1}\n",
    "\n",
    "How does your test score compare to the cross validation score `optimal_score` from **Question 1.15**? \n",
    "\n",
    "A) Our model's test score (`test_score`) is much higher than the cross validation score (`optimal_score`).\n",
    "\n",
    "B) Our model's test score (`test_score`) is much lower than the cross validation score (`optimal_score`).\n",
    "\n",
    "C) Our model's test score (`test_score`) is a little higher than the the cross validation score (`optimal_score`).\n",
    "\n",
    "D) Our model's test score (`test_score`) is a little lower than the the cross validation score (`optimal_score`)\n",
    "\n",
    "*Answer in the cell below using the uppercase letter associated with your answer. Place your answer between `\"\"`, assign the correct answer to an object called `answer3_3`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "77e163e3f07c0eedcabbdad699f9b881",
     "grade": false,
     "grade_id": "cell-df0c282f7501bad2",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent Difference : 0.12990080302314477\n",
      "Answer 3.3 : C\n"
     ]
    }
   ],
   "source": [
    "percent_diff = (test_score - optimal_score) / optimal_score * 100\n",
    "\n",
    "if percent_diff > 20 :\n",
    "    answer3_3 = 'A'\n",
    "elif percent_diff < -20 :\n",
    "    answer3_3 = 'B'\n",
    "elif percent_diff > 0 :\n",
    "    answer3_3 = 'C'\n",
    "else :\n",
    "    answer3_3 = 'D'\n",
    "\n",
    "print(f'Percent Difference : {percent_diff}')\n",
    "print(f'Answer 3.3 : {answer3_3}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "29af550efd490f14d5337d907dcd1218",
     "grade": true,
     "grade_id": "cell-bc4abdda953433b6",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_3_3(answer3_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.4** <br> {points: 1}\n",
    "\n",
    "Plot a confusion matrix on the test set using the object `random_search` as your estimator and `normalize=\"all\"` (see the [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.plot_confusion_matrix.html) for more help here).\n",
    "\n",
    "Name the plot `reviews_cm`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "79a7ec1f0d07a336b0c789d761593773",
     "grade": false,
     "grade_id": "cell-0fbf22092f07ba56",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f67123fdac0>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "reviews_cm = ConfusionMatrixDisplay(\n",
    "    confusion_matrix = confusion_matrix(\n",
    "        y_true = y_test, y_pred = best_model.predict(X_test),\n",
    "        normalize = 'all'\n",
    "    ), \n",
    "    display_labels = ['negative', 'positive']\n",
    ")\n",
    "\n",
    "reviews_cm.plot(cmap = 'Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d9e3d55c0d5b035277499b42c0b16099",
     "grade": true,
     "grade_id": "cell-77d2298dbbdbe59b",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_3_4(reviews_cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.5** <br> {points: 3}\n",
    "\n",
    "Print a classification report on the `X_test` predictions of the best model from `random_search` with measurements to 4 decimal places. Use this information to answer the following questions.\n",
    "\n",
    "A) What is the recall if we classify `pos` as our \"positive\" class? Save the result to 4 decimal places in an object named `answer3_5a`. \n",
    "\n",
    "B) What is the precision weighted average? Save the result to 4 decimal places in an object named `answer3_5b`. \n",
    "\n",
    "C) What is the `f1` score using `pos` as your positive class? Save the result to 4 decimal places in an object named `answer3_5c`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg     0.8577    0.8342    0.8458      5000\n",
      "         pos     0.8386    0.8616    0.8500      5000\n",
      "\n",
      "    accuracy                         0.8479     10000\n",
      "   macro avg     0.8482    0.8479    0.8479     10000\n",
      "weighted avg     0.8482    0.8479    0.8479     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(\n",
    "    y_true = y_test, y_pred = best_model.predict(X_test),\n",
    "    digits = 4\n",
    ")\n",
    "\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4171  829]\n",
      " [ 692 4308]]\n"
     ]
    }
   ],
   "source": [
    "matrix = confusion_matrix(\n",
    "    y_true = y_test, y_pred = best_model.predict(X_test),\n",
    "    labels = [x for x in best_model.classes_]\n",
    ")\n",
    "\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_pos = matrix[1, 1] / (matrix[1, 1] + matrix[0, 1])\n",
    "precision_neg = matrix[0, 0] / (matrix[0, 0] + matrix[1, 0])\n",
    "\n",
    "recall_pos = matrix[1, 1] / (matrix[1, 1] + matrix[1, 0])\n",
    "recall_neg = matrix[0, 0] / (matrix[0, 0] + matrix[0, 1])\n",
    "\n",
    "f1_pos = 2 * (precision_pos * recall_pos) / (precision_pos + recall_pos)\n",
    "f1_neg = 2 * (precision_neg * recall_neg) / (precision_neg + recall_neg)\n",
    "\n",
    "precision_weighted_avg = (f1_pos * (matrix[1, 1] + matrix[0, 1]) / (matrix.sum()))  + (f1_neg * (matrix[0, 0] + matrix[1, 0]) / (matrix.sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive Recall 0.8616\n",
      "Precision Weighted Average : 0.8479\n",
      "Positive F1 : 0.85\n"
     ]
    }
   ],
   "source": [
    "recall_pos = round(recall_pos, 4)\n",
    "precision_weighted_avg = round(precision_weighted_avg, 4)\n",
    "f1_pos = round(f1_pos, 4)\n",
    "\n",
    "print(f'Positive Recall {recall_pos}')\n",
    "print(f'Precision Weighted Average : {precision_weighted_avg}')\n",
    "print(f'Positive F1 : {f1_pos}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "382c58dca6bca53973f6c467c076c96a",
     "grade": false,
     "grade_id": "cell-28a036c0bedbe347",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "answer3_5a = recall_pos\n",
    "answer3_5b = precision_weighted_avg\n",
    "answer3_5c = f1_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f5590966ca4ffae5fc12be3b12de46b2",
     "grade": true,
     "grade_id": "cell-ef83e4c8c671b548",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_3_5_1(answer3_5a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "97d412d4041fb62879f54a7b0cb489c3",
     "grade": true,
     "grade_id": "cell-50eb8166cc91b52e",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_3_5_2(answer3_5b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f9adbc22a2dc5f00ecdb266c045fda13",
     "grade": true,
     "grade_id": "cell-69f01092aba39658",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_3_5_3(answer3_5c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.6** <br> {points: 2}\n",
    "\n",
    "Make a dataframe named `results_df` that contains these 5 columns: \n",
    "\n",
    "- `review` - this should contain the reviews from `X_test`.\n",
    "- `true_label` - This should contain the true `y_test` values. \n",
    "- `predicted_y` - The predicted labels generated from `best_model` for the `X_test` reviews. \n",
    "- `neg_label_prob` - The negative probabilities generated from `best_model` for the `X_test` reviews. These can be found at index 0 of the `predict_proba` output (you can get that using `[:,0]`). \n",
    "-  `pos_label_prob` - The negative probabilities generated from `best_model` for the `X_test` reviews. These can be found at index 0 of the `predict_proba` output (you can get that using `[:,1]`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ef699b6cc1eedb086b3181732d55f501",
     "grade": false,
     "grade_id": "cell-fd73ade995c4c656",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>true_label</th>\n",
       "      <th>predicted_y</th>\n",
       "      <th>neg_label_prob</th>\n",
       "      <th>pos_label_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Universal Studios version of \"Flipper\" (1996) ...</td>\n",
       "      <td>pos</td>\n",
       "      <td>pos</td>\n",
       "      <td>6.090454e-08</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is one of Bruce's most underrated films i...</td>\n",
       "      <td>pos</td>\n",
       "      <td>pos</td>\n",
       "      <td>1.515321e-07</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1904. The North African nation of Morocco is h...</td>\n",
       "      <td>pos</td>\n",
       "      <td>pos</td>\n",
       "      <td>4.482124e-07</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Many years ago I saw this movie (on television...</td>\n",
       "      <td>pos</td>\n",
       "      <td>pos</td>\n",
       "      <td>9.123248e-07</td>\n",
       "      <td>0.999999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ray Charles Robinson (Jamie Foxx) is a extreme...</td>\n",
       "      <td>pos</td>\n",
       "      <td>pos</td>\n",
       "      <td>1.783141e-06</td>\n",
       "      <td>0.999998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review true_label predicted_y  \\\n",
       "0  Universal Studios version of \"Flipper\" (1996) ...        pos         pos   \n",
       "1  This is one of Bruce's most underrated films i...        pos         pos   \n",
       "2  1904. The North African nation of Morocco is h...        pos         pos   \n",
       "3  Many years ago I saw this movie (on television...        pos         pos   \n",
       "4  Ray Charles Robinson (Jamie Foxx) is a extreme...        pos         pos   \n",
       "\n",
       "   neg_label_prob  pos_label_prob  \n",
       "0    6.090454e-08        1.000000  \n",
       "1    1.515321e-07        1.000000  \n",
       "2    4.482124e-07        1.000000  \n",
       "3    9.123248e-07        0.999999  \n",
       "4    1.783141e-06        0.999998  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_df = pd.DataFrame(\n",
    "    data = {\n",
    "        'review' : X_test,\n",
    "        'true_label' : y_test,\n",
    "        'predicted_y' : best_model.predict(X_test),\n",
    "        'neg_label_prob' : best_model.predict_proba(X_test)[:, 0],\n",
    "        'pos_label_prob' : best_model.predict_proba(X_test)[:, 1]\n",
    "    }\n",
    ").sort_values(by = 'pos_label_prob', ascending = False).reset_index(drop = True)\n",
    "\n",
    "display(results_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a17c40bfd580ac8691a51f29a0467d65",
     "grade": true,
     "grade_id": "cell-c7d6580c13a97fbd",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_3_6(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.7** <br> {points: 1}\n",
    "\n",
    "Find the top 5 movie reviews in `results_df` with the highest predicted probability of being positive (i.e., where the model is most confident that the review is positive).\n",
    "\n",
    "Save the reviews and the associated probability score in a dataframe named `most_pos_df`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fcf976112f3bfc87ba1752ea0e73f79a",
     "grade": false,
     "grade_id": "cell-2efd1cb1fb505acc",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>true_label</th>\n",
       "      <th>predicted_y</th>\n",
       "      <th>neg_label_prob</th>\n",
       "      <th>pos_label_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Universal Studios version of \"Flipper\" (1996) ...</td>\n",
       "      <td>pos</td>\n",
       "      <td>pos</td>\n",
       "      <td>6.090454e-08</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is one of Bruce's most underrated films i...</td>\n",
       "      <td>pos</td>\n",
       "      <td>pos</td>\n",
       "      <td>1.515321e-07</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1904. The North African nation of Morocco is h...</td>\n",
       "      <td>pos</td>\n",
       "      <td>pos</td>\n",
       "      <td>4.482124e-07</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Many years ago I saw this movie (on television...</td>\n",
       "      <td>pos</td>\n",
       "      <td>pos</td>\n",
       "      <td>9.123248e-07</td>\n",
       "      <td>0.999999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ray Charles Robinson (Jamie Foxx) is a extreme...</td>\n",
       "      <td>pos</td>\n",
       "      <td>pos</td>\n",
       "      <td>1.783141e-06</td>\n",
       "      <td>0.999998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review true_label predicted_y  \\\n",
       "0  Universal Studios version of \"Flipper\" (1996) ...        pos         pos   \n",
       "1  This is one of Bruce's most underrated films i...        pos         pos   \n",
       "2  1904. The North African nation of Morocco is h...        pos         pos   \n",
       "3  Many years ago I saw this movie (on television...        pos         pos   \n",
       "4  Ray Charles Robinson (Jamie Foxx) is a extreme...        pos         pos   \n",
       "\n",
       "   neg_label_prob  pos_label_prob  \n",
       "0    6.090454e-08        1.000000  \n",
       "1    1.515321e-07        1.000000  \n",
       "2    4.482124e-07        1.000000  \n",
       "3    9.123248e-07        0.999999  \n",
       "4    1.783141e-06        0.999998  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "most_pos_df = results_df.sort_values(by = 'pos_label_prob', ascending = False).head(5).reset_index(drop = True)\n",
    "\n",
    "display(most_pos_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bbcf447413876f3d524544ec91b29280",
     "grade": true,
     "grade_id": "cell-0bb36bd74b4871e3",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_3_7(most_pos_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feel free to explore these reviews and see how positive they read!\n",
    "\n",
    "Here is the first one for you (if you got the above question right)! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Universal Studios version of \"Flipper\" (1996) is a great heartwarming film for the entire family with good values and sentimentality. It is the story of Sandy Ricks, a teenager from Chicago who reluctantly spends his vacation with his Uncle Porter Ricks in the Bahamas. This ultimately changes the teenagers life and he grows up in the process. He learns to appreciate nature and to have a respect for the environment. I grew up in the 1960's and the NBC television show \"Flipper\" was my favorite childhood show. Elijah Wood is perfectly cast as a 1990's Sandy Ricks and gives an excellent performance. As much as I liked the NBC television show and MGM theatrical feature films with Luke Halpin as Sandy in the 1960's I liked this feature the best! I feel Elijah Wood is the best Sandy Ricks. With respect to Luke Halpin I feel Elijah Wood has more of a range of acting talent and emotes more as an actor which makes his performance excellent and more believable. I think Elijah Wood is the best young actor working today in films. Director Alan Shapiro also wrote the screenplay and has done an excellent job as both writer and director of this film. Paul Hogan gives a comical and likable performance as Sandy's Uncle Porter Ricks. Mr. Hogan's performance perfectly offsets Elijah's role as Sandy. I am a big fan of underwater films. This film was beautifully shot in the Bahamas like \"Thunderball\" (1965 UA) was. The director of photography was Bill Butler A.S.C. who lensed the film \"Jaws\" in 1975. Mr. Butler is a very talented cinematographer. The underwater director of photography was Pete Romano. He did a superb job with the underwater cinematography. I enjoyed the film score by Joel McNeely. This good film score featured Crosby, Stills and Nash among other talented artists. This motion picture was shot in Panavision like \"Thunderball\" in the aspect ratio of 2.35:1 If possible try to see this film in a scope version as originally framed and visioned by Alan Shapiro and Bill Butler. Another very nice thing is that Mr. Shapiro gave the \"original\" Sandy Ricks (Luke Halpin) a small part in this remake. He portrayed Bounty Fisherman #3 in this film. This was a very kind gesture on Mr. Shapiro's part! As you can tell I am a real true fan of this film. Sadly this beautiful film was met with harsh words by the majority of movie critics. I originally saw this movie on my birthday, May 31st of 1996 in a movie theater. It meant a lot to me. I have it on numerous video versions. The VHS versions are in \"pan and scan\". The laserdisc version is \"letterboxed\" 2.35:1! I even have a VCD in 2.35:1 from Hong Kong which is \"letterboxed\". But my most prized possession is an \"original\" 16mm theatrical feature print which I will treasure for the rest of my life! Thank you Mr. Shapiro, Elijah Wood, Paul Hogan and everyone involved for making this a memorable movie for me to enjoy!<br /><br />P.S. I must add that the quality of the Universal DVD is superb! It is the best DVD as far as quality I have ever seen. The color and resolution is spectacular. The soundtrack is great. I think Universal must have used the same transfer for the DVD that they did for the laserdisc version. The 35mm scope print is \"mint\" and Alan's film really has a wonderful look to it. A great tribute to a wonderful film! The DVD's resolution is even superior to the laserdisc quality! It's just spectacular! Thank you Universal Home Video for the great quality control and transfer. Many thank's for doing a superb job on this wonderful family film. Also many thank's to you Alan for all your extreme kindness to me!!! It's a real honor to know you!!! (Review Revised/Updated June 27, 2005)\n"
     ]
    }
   ],
   "source": [
    "print(most_pos_df.iloc[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Universal Studios version of \"Flipper\" (1996) is a great heartwarming film for the entire family with good values and sentimentality. It is the story of Sandy Ricks, a teenager from Chicago who reluctantly spends his vacation with his Uncle Porter Ricks in the Bahamas. This ultimately changes the teenagers life and he grows up in the process. He learns to appreciate nature and to have a respect for the environment. I grew up in the 1960's and the NBC television show \"Flipper\" was my favorite childhood show. Elijah Wood is perfectly cast as a 1990's Sandy Ricks and gives an excellent performance. As much as I liked the NBC television show and MGM theatrical feature films with Luke Halpin as Sandy in the 1960's I liked this feature the best! I feel Elijah Wood is the best Sandy Ricks. With respect to Luke Halpin I feel Elijah Wood has more of a range of acting talent and emotes more as an actor which makes his performance excellent and more believable. I think Elijah Wood is the best young actor working today in films. Director Alan Shapiro also wrote the screenplay and has done an excellent job as both writer and director of this film. Paul Hogan gives a comical and likable performance as Sandy's Uncle Porter Ricks. Mr. Hogan's performance perfectly offsets Elijah's role as Sandy. I am a big fan of underwater films. This film was beautifully shot in the Bahamas like \"Thunderball\" (1965 UA) was. The director of photography was Bill Butler A.S.C. who lensed the film \"Jaws\" in 1975. Mr. Butler is a very talented cinematographer. The underwater director of photography was Pete Romano. He did a superb job with the underwater cinematography. I enjoyed the film score by Joel McNeely. This good film score featured Crosby, Stills and Nash among other talented artists. This motion picture was shot in Panavision like \"Thunderball\" in the aspect ratio of 2.35:1 If possible try to see this film in a scope version as originally framed and visioned by Alan Shapiro and Bill Butler. Another very nice thing is that Mr. Shapiro gave the \"original\" Sandy Ricks (Luke Halpin) a small part in this remake. He portrayed Bounty Fisherman #3 in this film. This was a very kind gesture on Mr. Shapiro's part! As you can tell I am a real true fan of this film. Sadly this beautiful film was met with harsh words by the majority of movie critics. I originally saw this movie on my birthday, May 31st of 1996 in a movie theater. It meant a lot to me. I have it on numerous video versions. The VHS versions are in \"pan and scan\". The laserdisc version is \"letterboxed\" 2.35:1! I even have a VCD in 2.35:1 from Hong Kong which is \"letterboxed\". But my most prized possession is an \"original\" 16mm theatrical feature print which I will treasure for the rest of my life! Thank you Mr. Shapiro, Elijah Wood, Paul Hogan and everyone involved for making this a memorable movie for me to enjoy!<br /><br />P.S. I must add that the quality of the Universal DVD is superb! It is the best DVD as far as quality I have ever seen. The color and resolution is spectacular. The soundtrack is great. I think Universal must have used the same transfer for the DVD that they did for the laserdisc version. The 35mm scope print is \"mint\" and Alan's film really has a wonderful look to it. A great tribute to a wonderful film! The DVD's resolution is even superior to the laserdisc quality! It's just spectacular! Thank you Universal Home Video for the great quality control and transfer. Many thank's for doing a superb job on this wonderful family film. Also many thank's to you Alan for all your extreme kindness to me!!! It's a real honor to know you!!! (Review Revised/Updated June 27, 2005)\n"
     ]
    }
   ],
   "source": [
    "print(most_pos_df.iloc[0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.8** <br> {points: 1}\n",
    "\n",
    "Using `best_model`, find the 5 movie reviews in the test set with the highest predicted probability of being negative (i.e., where the model is most confident that the review is negative).\n",
    "\n",
    "Save the reviews and the associated probability score in a dataframe named `most_neg_df`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "362d15028ab4eae0e106c0813abbd11d",
     "grade": false,
     "grade_id": "cell-30038642ed474e31",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>true_label</th>\n",
       "      <th>predicted_y</th>\n",
       "      <th>neg_label_prob</th>\n",
       "      <th>pos_label_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>Plankton, or Creatures from the Abyss as I'm p...</td>\n",
       "      <td>neg</td>\n",
       "      <td>neg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.701106e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>The review on the main page admits that the mo...</td>\n",
       "      <td>neg</td>\n",
       "      <td>neg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.155311e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>Komodo vs. Cobra starts as 'One Planet' enviro...</td>\n",
       "      <td>neg</td>\n",
       "      <td>neg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.946306e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>WEll first and for most I'd just like to say t...</td>\n",
       "      <td>neg</td>\n",
       "      <td>neg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.654804e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>I don't understand jokes. I do believe this is...</td>\n",
       "      <td>neg</td>\n",
       "      <td>neg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.595324e-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 review true_label  \\\n",
       "9999  Plankton, or Creatures from the Abyss as I'm p...        neg   \n",
       "9998  The review on the main page admits that the mo...        neg   \n",
       "9997  Komodo vs. Cobra starts as 'One Planet' enviro...        neg   \n",
       "9996  WEll first and for most I'd just like to say t...        neg   \n",
       "9995  I don't understand jokes. I do believe this is...        neg   \n",
       "\n",
       "     predicted_y  neg_label_prob  pos_label_prob  \n",
       "9999         neg             1.0    3.701106e-09  \n",
       "9998         neg             1.0    4.155311e-09  \n",
       "9997         neg             1.0    8.946306e-09  \n",
       "9996         neg             1.0    1.654804e-08  \n",
       "9995         neg             1.0    3.595324e-08  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "most_neg_df = results_df.sort_values(by = 'pos_label_prob', ascending = True).head(5)\n",
    "\n",
    "display(most_neg_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dd6d7b1e1433b5653781d92ed528c5e5",
     "grade": true,
     "grade_id": "cell-20c66de412c3ec6a",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_3_8(most_neg_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And what does a negative review read like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plankton, or Creatures from the Abyss as I'm positive it's more commonly known as & filmed under as the title Creatures from the Abyss appears over a moving image & in the same font type as the rest of the credits, starts with five 20 something kids, Mike (Clay Rogers) his girlfriend Margaret (Sharon Twomey), sisters Julie (Ann Wolf) & Dorothy (Loren DePalm) & an annoying idiot named Bobby (Michael Bon) whom decide to all fit into a small rubber boat & head out to sea, don't ask why as I don't know. Oh & the complete idiot Bobby left the petrol behind & never thought to tell anyone so it comes as no great surprise that they end up stranded out at sea without any petrol for the motor & to make matters worse they become trapped in a thunder storm & discover a dead body floating in the water. Shortly after their luck seems to change when they come across a yacht & potential safety, in a flash everyone boards the yacht & begin to explore. First of all they find a scientific lab with various fish specimens & computer equipment, then down below they find fully furnished & luxurious cabins. They find a chemist (Deran Sarafian) who appears mad & can't talk. They eat fish from the fridge which makes Dorothy puke up green vomit, beetles & slugs. They learn that these fish are living fossil's 1000's of years old & have been contaminated by toxic waste dumped in the sea & that they fly, mutate, bite & are generally unpleasant to be around. I really can't be bothered to go on with this plot outline so I won't, here's what I think...<br /><br />This Italian production was produced & directed by Massimiliano Cerchi under the pseudonym Al Passeri (I'd hide under a different name if I made a film this bad too) & I think Plankton is quite simply one of the worst films ever, there are so many things wrong with this film it's difficult to know where to start. First the script by Richard Baumann is total crap, it makes no sense whatsoever & is so slow & dull it was torture for me to sit through. Why would five people just simply set sail for the middle of the ocean on a rubber dinghy barely big enough to fit them all in? What were they planning on doing exactly? Why do we often get point-of-view shots from these fish creatures but they seem to be totally invisible to the characters as they are never shown on screen even though they are right next to a character, & how do these fish get around the boat as there is no water for them to swim in? People's actions & reactions to things are all wrong, they constantly split up, they make bizarre decisions that simply don't make any sense in the situation they find themselves in & some of the dialogue is as awful as anything I've heard. I could go on all day about all the plot holes & ridiculous goings on but I'll run out of space if I do. The fish creatures themselves look awful, a mixture of rubbish rubber puppets & some really bad stop motion animation at the end, the scenes where they interact with the human cast also look terrible with some bad super imposition. I have heard a lot of comments saying that Plankton is gory, don't make me laugh! Forget it there is virtually no blood or gore in Plankton whatsoever, there are a couple of slimy scenes when Bobby transforms into a fish monster while having sex with Julie but it's pretty brief & he doesn't kill her, he just sort of drips slime on her, grows a couple of tentacles & a fish head comes out of his mouth. Later on Julie's vagina starts to drip some dark slime but that's it, we never get to actually see what happens to her or what the slime is. Dorothy has a fish creature come out of her back, off screen, & control her but again we never get to see what happens to her while Margaret commits suicide, a very brief shot of a plastic harpoon stuck to her forehead. Easily the grossest scene is when Dorothy pukes up that green stuff with what looks like beetles & slugs in it. That's it, only one person actually dies on screen & for the most part Plankton is quite tame & as exciting as watching paint dry & I nearly fell asleep it's so boring. I can't see how anybody can like this total crap, I just can't. The acting is awful, the dubbing is awful, the characters are awful & I hated all of them. Tecnically Plankton is predictably crap as well, with an estimated budget of only $250,000 all I can say is where did the money go? The sets are monotonous & dull with one lab & a few cabins, the special effect's are bottom of the barrel stuff including the most fake looking exploding boat ever, the cinematography is bland, the music sucks there is zero atmosphere or tension & as a whole Plankton, like it's name sake, is as low in the food chain as it could possibly be. I hate Plankton, it's awful in every single aspect of it's overlong 86 minute duration. Do yourself a favour & avoid this one at all costs unless your either a masochist or insomniac.\n"
     ]
    }
   ],
   "source": [
    "print(most_neg_df.iloc[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plankton, or Creatures from the Abyss as I'm positive it's more commonly known as & filmed under as the title Creatures from the Abyss appears over a moving image & in the same font type as the rest of the credits, starts with five 20 something kids, Mike (Clay Rogers) his girlfriend Margaret (Sharon Twomey), sisters Julie (Ann Wolf) & Dorothy (Loren DePalm) & an annoying idiot named Bobby (Michael Bon) whom decide to all fit into a small rubber boat & head out to sea, don't ask why as I don't know. Oh & the complete idiot Bobby left the petrol behind & never thought to tell anyone so it comes as no great surprise that they end up stranded out at sea without any petrol for the motor & to make matters worse they become trapped in a thunder storm & discover a dead body floating in the water. Shortly after their luck seems to change when they come across a yacht & potential safety, in a flash everyone boards the yacht & begin to explore. First of all they find a scientific lab with various fish specimens & computer equipment, then down below they find fully furnished & luxurious cabins. They find a chemist (Deran Sarafian) who appears mad & can't talk. They eat fish from the fridge which makes Dorothy puke up green vomit, beetles & slugs. They learn that these fish are living fossil's 1000's of years old & have been contaminated by toxic waste dumped in the sea & that they fly, mutate, bite & are generally unpleasant to be around. I really can't be bothered to go on with this plot outline so I won't, here's what I think...<br /><br />This Italian production was produced & directed by Massimiliano Cerchi under the pseudonym Al Passeri (I'd hide under a different name if I made a film this bad too) & I think Plankton is quite simply one of the worst films ever, there are so many things wrong with this film it's difficult to know where to start. First the script by Richard Baumann is total crap, it makes no sense whatsoever & is so slow & dull it was torture for me to sit through. Why would five people just simply set sail for the middle of the ocean on a rubber dinghy barely big enough to fit them all in? What were they planning on doing exactly? Why do we often get point-of-view shots from these fish creatures but they seem to be totally invisible to the characters as they are never shown on screen even though they are right next to a character, & how do these fish get around the boat as there is no water for them to swim in? People's actions & reactions to things are all wrong, they constantly split up, they make bizarre decisions that simply don't make any sense in the situation they find themselves in & some of the dialogue is as awful as anything I've heard. I could go on all day about all the plot holes & ridiculous goings on but I'll run out of space if I do. The fish creatures themselves look awful, a mixture of rubbish rubber puppets & some really bad stop motion animation at the end, the scenes where they interact with the human cast also look terrible with some bad super imposition. I have heard a lot of comments saying that Plankton is gory, don't make me laugh! Forget it there is virtually no blood or gore in Plankton whatsoever, there are a couple of slimy scenes when Bobby transforms into a fish monster while having sex with Julie but it's pretty brief & he doesn't kill her, he just sort of drips slime on her, grows a couple of tentacles & a fish head comes out of his mouth. Later on Julie's vagina starts to drip some dark slime but that's it, we never get to actually see what happens to her or what the slime is. Dorothy has a fish creature come out of her back, off screen, & control her but again we never get to see what happens to her while Margaret commits suicide, a very brief shot of a plastic harpoon stuck to her forehead. Easily the grossest scene is when Dorothy pukes up that green stuff with what looks like beetles & slugs in it. That's it, only one person actually dies on screen & for the most part Plankton is quite tame & as exciting as watching paint dry & I nearly fell asleep it's so boring. I can't see how anybody can like this total crap, I just can't. The acting is awful, the dubbing is awful, the characters are awful & I hated all of them. Tecnically Plankton is predictably crap as well, with an estimated budget of only $250,000 all I can say is where did the money go? The sets are monotonous & dull with one lab & a few cabins, the special effect's are bottom of the barrel stuff including the most fake looking exploding boat ever, the cinematography is bland, the music sucks there is zero atmosphere or tension & as a whole Plankton, like it's name sake, is as low in the food chain as it could possibly be. I hate Plankton, it's awful in every single aspect of it's overlong 86 minute duration. Do yourself a favour & avoid this one at all costs unless your either a masochist or insomniac.\n"
     ]
    }
   ],
   "source": [
    "print(most_neg_df.iloc[0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.9 - Optional** <br> {points: 0}\n",
    "This is an optional question!\n",
    "\n",
    "(You'll get 0 marks for this one but you may have fun doing it?!) \n",
    "\n",
    "Using `best_model`, find the 5 movie reviews in the test set with the most divided probability of being negative or positive (i.e., where the model is least confident in either review sentiment).\n",
    "\n",
    "Save the reviews and the associated probability score in a dataframe named `divided_revs_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5f1e658fb2a70bd0dcc73eca848e0c37",
     "grade": false,
     "grade_id": "cell-d4bcc26bae26cd03",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>true_label</th>\n",
       "      <th>predicted_y</th>\n",
       "      <th>neg_label_prob</th>\n",
       "      <th>pos_label_prob</th>\n",
       "      <th>prob_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Some may go for a film like this but I most as...</td>\n",
       "      <td>neg</td>\n",
       "      <td>neg</td>\n",
       "      <td>0.500013</td>\n",
       "      <td>0.499987</td>\n",
       "      <td>0.000026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>First of all, I'd like to say that I really en...</td>\n",
       "      <td>neg</td>\n",
       "      <td>neg</td>\n",
       "      <td>0.500045</td>\n",
       "      <td>0.499955</td>\n",
       "      <td>0.000090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Generally political messages are done on telev...</td>\n",
       "      <td>neg</td>\n",
       "      <td>pos</td>\n",
       "      <td>0.499806</td>\n",
       "      <td>0.500194</td>\n",
       "      <td>0.000389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Two stars &lt;br /&gt;&lt;br /&gt;Amanda Plummer looking l...</td>\n",
       "      <td>neg</td>\n",
       "      <td>pos</td>\n",
       "      <td>0.499743</td>\n",
       "      <td>0.500257</td>\n",
       "      <td>0.000514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(WARNING - CONTAINS MILD SPOILER) A movie almo...</td>\n",
       "      <td>pos</td>\n",
       "      <td>neg</td>\n",
       "      <td>0.500445</td>\n",
       "      <td>0.499555</td>\n",
       "      <td>0.000889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review true_label predicted_y  \\\n",
       "0  Some may go for a film like this but I most as...        neg         neg   \n",
       "1  First of all, I'd like to say that I really en...        neg         neg   \n",
       "2  Generally political messages are done on telev...        neg         pos   \n",
       "3  Two stars <br /><br />Amanda Plummer looking l...        neg         pos   \n",
       "4  (WARNING - CONTAINS MILD SPOILER) A movie almo...        pos         neg   \n",
       "\n",
       "   neg_label_prob  pos_label_prob  prob_diff  \n",
       "0        0.500013        0.499987   0.000026  \n",
       "1        0.500045        0.499955   0.000090  \n",
       "2        0.499806        0.500194   0.000389  \n",
       "3        0.499743        0.500257   0.000514  \n",
       "4        0.500445        0.499555   0.000889  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "divided_revs_df = results_df.assign(prob_diff = abs(results_df['pos_label_prob'] - results_df['neg_label_prob']))\n",
    "divided_revs_df.sort_values(by = 'prob_diff', ascending = True, inplace = True)\n",
    "divided_revs_df = divided_revs_df.head(5).reset_index(drop = True)\n",
    "\n",
    "display(divided_revs_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0d455165c2d215f8f19e93882b08dd3d",
     "grade": true,
     "grade_id": "cell-b283c65b111507ce",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_3_9(divided_revs_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you attempted this question, uncomment the code below and read a review that the model was uncertain on classifying."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some may go for a film like this but I most assuredly did not. A college professor, David Norwell, suddenly gets a yen for adoption. He pretty much takes the first child offered, a bad choice named Adam. As it turns out Adam doesn't have both oars in the water which, almost immediately, causes untold stress and turmoil for Dr. Norwell. This sob story drolly played out with one problem after another, all centered around Adam's inabilities and seizures. Why Norwell wanted to complicate his life with an unknown factor like an adoptive child was never explained. Along the way the good doctor managed to attract a wifey to share in all the hell the little one was dishing out. Personally, I think both of them were one beer short of a sixpack. Bypass this yawner.\n"
     ]
    }
   ],
   "source": [
    "print(divided_revs_df.iloc[0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.10 - Optional** <br> {points: 0}\n",
    "\n",
    "Here is another optional question!\n",
    "\n",
    "Examine a review from the test set where our `best_model` is making mistakes, i.e., where the true labels do not match the predicted labels. \n",
    "\n",
    "Save a (single) full row from `divided_revs_df` in an object named `wrong_review`. (We are expected a dataframe as the datatype for the autograder). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1017b2552127e609303dfc185646b2ed",
     "grade": false,
     "grade_id": "cell-2bd2d437b5dfa725",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>true_label</th>\n",
       "      <th>predicted_y</th>\n",
       "      <th>neg_label_prob</th>\n",
       "      <th>pos_label_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>Yet another version of mother of all gangster ...</td>\n",
       "      <td>neg</td>\n",
       "      <td>pos</td>\n",
       "      <td>0.000581</td>\n",
       "      <td>0.999419</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               review true_label predicted_y  \\\n",
       "87  Yet another version of mother of all gangster ...        neg         pos   \n",
       "\n",
       "    neg_label_prob  pos_label_prob  \n",
       "87        0.000581        0.999419  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wrong_review = results_df[results_df['true_label'] != results_df['predicted_y']].head(1)\n",
    "\n",
    "display(wrong_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d9cf203b60431413312896457820f942",
     "grade": true,
     "grade_id": "cell-dee648fb1283ea86",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_3_10(wrong_review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you attempted this question, uncomment the code below and read the review below. Does it make sense as to why the model got it wrong?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yet another version of mother of all gangster flicks-the Classic \"Godfather\" and yet another case of over-hype due to media circus. Sarkar, the 13th Hindi film of Ram Gopal Varma as director is also the weakest in his Underworld trilogy including the other two being the excellent-Satya and Company. The Charisma, the magnetic persona of the two Bachchans playing father-son duo on screen for the first time is definitely a treat to watch out for. Not just strong performances but their perfect chemistry is the biggest scoring point here for which Varma should be applauded. However, the same equation of the duo is missing with the other characters in the film. Reason-the other characters look more like cardboard caricatures esp. the villains represent the typical Bollywood baddies. A character who attracts attention is elder son played by Kaykay but again not able to hold due to half-baked characterization. . The Drama and conflict is brought alive by the excessive use of Close-shots, which brought a claustrophobic effect rightly needed to construct an ambiance. The haunting Score (Amar Mohile) and the sound design (Kunal Mehta, Parikshit Lalwani & Anup Dev), together with dark, murky background overlapped by shinning powerful images (camerawork by Amit Roy) contributes to Visuals so typical of Ramu's style. But there is an overuse of Music though fortunately no songs are there in the film. But can interest of today's \"intelligently growing\" audience be sustained just on shoulders of two performers and strong Visuals ? I don't think so. Surely, audience \"maangey more\" and here film fails to deliver. In any adaptation, in order to add a new dimension, the biggest pre-requisite is the Screenplay, which is sluggish here not being crisp at places, and therefore the pace slackens quite often. What finally audience is subjected to is a highly predictable, very commonplace drama with very little surprise elements. Top Stunt director Allan Amin Ghani is also not in his best form. Some scenes which require a different treatment includes- a Minister is talking foul about Sarkar and the son is overhearing; a very amateurish shoot out in the jail on Sarkar, Sarkar Jr. escapes from the clutches of his enemies, a Son easily motivated to kill his own father, a son is secretly entering his father's room to kill him, a police commissioner slapping Sarkar Jr-all this requires a more realistic, hard-hitting approach which is the back-bone to create the required conflict. The dialogues are weak for eg. look at an amateurish line where a CM says to Sarkar Jr. Â?\"Wo jo Police Commissioner tha na usay maine hata diya\".. The women folk take on Sarkar's working is completely ignored. The uninterrupted negotiations about criminal activities while Sarkar is with his family also look slightly out of place In fact, the film follows a graph quite similar to Ramu's own production-Ab Tak Chhappan. In depicting the battle between good and evil, the other side of life-the law, police, administration, politics is completely ignored. Certainly, more is expected in content. Here the film definitely falls short and could not rise above an average fare. Dear Ramu, agreed that now you are laughing your way to the bank, you definitely need to take some drastic overhauling measures in your film production factory, before it is too late.\n"
     ]
    }
   ],
   "source": [
    "print(wrong_review.iloc[0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attributions\n",
    "- The IMDB DataSet - [Kaggle](https://www.kaggle.com/utathya/imdb-review-dataset)\n",
    "\n",
    "- MDS DSCI 571 - Supervised Learning I - [MDS's GitHub website](https://github.com/UBC-MDS/DSCI_571_sup-learn-1) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before Submitting \n",
    "\n",
    "Before submitting your assignment please do the following:\n",
    "\n",
    "- Read through your solutions\n",
    "- **Restart your kernel and clear output and rerun your cells from top to bottom** \n",
    "- Makes sure that none of your code is broken \n",
    "- Verify that the tests from the questions you answered have obtained the output \"Success\"\n",
    "\n",
    "This is a simple way to make sure that you are submitting all the variables needed to mark the assignment. This method should help avoid losing marks due to changes in your environment.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
